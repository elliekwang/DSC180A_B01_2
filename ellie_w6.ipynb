{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537746e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d96259",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc1fe1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONS_PATH = \"/uss/hdsi-prismdata/q2-ucsd-consDF.pqt\"\n",
    "ACCT_PATH = \"/uss/hdsi-prismdata/q2-ucsd-acctDF.pqt\"\n",
    "TRXN_PATH = \"/uss/hdsi-prismdata/q2-ucsd-trxnDF.pqt\"\n",
    "CATMAP_PATH = \"/uss/hdsi-prismdata/q2-ucsd-cat-map.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "261b8e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consdf: (15000, 4)\n",
      "acctdf: (24466, 5)\n",
      "trxndf: (6407321, 6)\n",
      "cat_map: (50, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "consdf = pd.read_parquet(CONS_PATH)\n",
    "acctdf = pd.read_parquet(ACCT_PATH)\n",
    "trxndf = pd.read_parquet(TRXN_PATH)\n",
    "cat_map = pd.read_csv(CATMAP_PATH)\n",
    "\n",
    "print(\"consdf:\", consdf.shape)\n",
    "print(\"acctdf:\", acctdf.shape)\n",
    "print(\"trxndf:\", trxndf.shape)\n",
    "print(\"cat_map:\", cat_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "50098c16-0977-436e-9962-683af758dbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>evaluation_date</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>DQ_TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>726.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>626.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>680.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>734.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>676.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>14995</td>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>655.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>14996</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>625.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>14997</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>688.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>14998</td>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>722.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>14999</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>751.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prism_consumer_id evaluation_date  credit_score  DQ_TARGET\n",
       "0                     0      2021-09-01         726.0        0.0\n",
       "1                     1      2021-07-01         626.0        0.0\n",
       "2                     2      2021-05-01         680.0        0.0\n",
       "3                     3      2021-03-01         734.0        0.0\n",
       "4                     4      2021-10-01         676.0        0.0\n",
       "...                 ...             ...           ...        ...\n",
       "14995             14995      2022-03-08         655.0        NaN\n",
       "14996             14996      2022-01-15         625.0        NaN\n",
       "14997             14997      2022-01-31         688.0        NaN\n",
       "14998             14998      2022-03-08         722.0        NaN\n",
       "14999             14999      2022-02-12         751.0        NaN\n",
       "\n",
       "[15000 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00aca813-b6c1-4b05-8eda-47a516572472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_account_id</th>\n",
       "      <th>account_type</th>\n",
       "      <th>balance_date</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3023</td>\n",
       "      <td>0</td>\n",
       "      <td>SAVINGS</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>90.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3023</td>\n",
       "      <td>1</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>225.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4416</td>\n",
       "      <td>2</td>\n",
       "      <td>SAVINGS</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>15157.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4416</td>\n",
       "      <td>3</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>66.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4227</td>\n",
       "      <td>4</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>7042.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24461</th>\n",
       "      <td>11500</td>\n",
       "      <td>24461</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-27</td>\n",
       "      <td>732.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24462</th>\n",
       "      <td>11615</td>\n",
       "      <td>24462</td>\n",
       "      <td>SAVINGS</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24463</th>\n",
       "      <td>11615</td>\n",
       "      <td>24463</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>1956.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24464</th>\n",
       "      <td>12210</td>\n",
       "      <td>24464</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>2701.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24465</th>\n",
       "      <td>11615</td>\n",
       "      <td>24465</td>\n",
       "      <td>CHECKING</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>7967.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24466 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prism_consumer_id prism_account_id account_type balance_date   balance\n",
       "0                  3023                0      SAVINGS   2021-08-31     90.57\n",
       "1                  3023                1     CHECKING   2021-08-31    225.95\n",
       "2                  4416                2      SAVINGS   2022-03-31  15157.17\n",
       "3                  4416                3     CHECKING   2022-03-31     66.42\n",
       "4                  4227                4     CHECKING   2021-07-31   7042.90\n",
       "...                 ...              ...          ...          ...       ...\n",
       "24461             11500            24461     CHECKING   2022-03-27    732.75\n",
       "24462             11615            24462      SAVINGS   2022-03-30      5.00\n",
       "24463             11615            24463     CHECKING   2022-03-30   1956.46\n",
       "24464             12210            24464     CHECKING   2022-03-28   2701.51\n",
       "24465             11615            24465     CHECKING   2022-03-30   7967.45\n",
       "\n",
       "[24466 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acctdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "815d579c-cd47-4b55-a65a-fb2fcb463846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_transaction_id</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>credit_or_debit</th>\n",
       "      <th>posted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3023</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3023</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>481.56</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3023</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3023</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3023</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2021-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407316</th>\n",
       "      <td>10533</td>\n",
       "      <td>6405304</td>\n",
       "      <td>31</td>\n",
       "      <td>4.96</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2022-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407317</th>\n",
       "      <td>10533</td>\n",
       "      <td>6405305</td>\n",
       "      <td>12</td>\n",
       "      <td>63.48</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2022-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407318</th>\n",
       "      <td>10533</td>\n",
       "      <td>6405306</td>\n",
       "      <td>12</td>\n",
       "      <td>53.99</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2022-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407319</th>\n",
       "      <td>10533</td>\n",
       "      <td>6405307</td>\n",
       "      <td>12</td>\n",
       "      <td>175.98</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2022-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407320</th>\n",
       "      <td>10533</td>\n",
       "      <td>6405308</td>\n",
       "      <td>14</td>\n",
       "      <td>16.04</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2022-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6407321 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        prism_consumer_id prism_transaction_id  category  amount  \\\n",
       "0                    3023                    0         4    0.05   \n",
       "1                    3023                    1        12  481.56   \n",
       "2                    3023                    2         4    0.05   \n",
       "3                    3023                    3         4    0.07   \n",
       "4                    3023                    4         4    0.06   \n",
       "...                   ...                  ...       ...     ...   \n",
       "6407316             10533              6405304        31    4.96   \n",
       "6407317             10533              6405305        12   63.48   \n",
       "6407318             10533              6405306        12   53.99   \n",
       "6407319             10533              6405307        12  175.98   \n",
       "6407320             10533              6405308        14   16.04   \n",
       "\n",
       "        credit_or_debit posted_date  \n",
       "0                CREDIT  2021-04-16  \n",
       "1                CREDIT  2021-04-30  \n",
       "2                CREDIT  2021-05-16  \n",
       "3                CREDIT  2021-06-16  \n",
       "4                CREDIT  2021-07-16  \n",
       "...                 ...         ...  \n",
       "6407316           DEBIT  2022-03-11  \n",
       "6407317           DEBIT  2022-03-30  \n",
       "6407318           DEBIT  2022-03-30  \n",
       "6407319           DEBIT  2022-03-31  \n",
       "6407320           DEBIT  2022-03-31  \n",
       "\n",
       "[6407321 rows x 6 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trxndf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44608c47-d9df-4f01-b022-b649e8e6973b",
   "metadata": {},
   "source": [
    "## data cleaning/prepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aada8276-99b0-4333-a80a-d3e711129f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "consdf = consdf.copy()\n",
    "consdf[\"evaluation_date\"] = pd.to_datetime(consdf[\"evaluation_date\"], errors=\"coerce\")\n",
    "\n",
    "# drop missing DQ_TARGET\n",
    "consdf = consdf[consdf[\"DQ_TARGET\"].notna()].copy()\n",
    "consdf[\"DQ_TARGET\"] = consdf[\"DQ_TARGET\"].astype(int)\n",
    "\n",
    "acctdf = acctdf.copy()\n",
    "acctdf[\"balance_date\"] = pd.to_datetime(acctdf[\"balance_date\"], errors=\"coerce\")\n",
    "\n",
    "trxndf = trxndf.copy()\n",
    "trxndf[\"posted_date\"] = pd.to_datetime(trxndf[\"posted_date\"], errors=\"coerce\")\n",
    "\n",
    "# Deduplicate transactions (use this whenever you build transaction features)\n",
    "trxndf = (\n",
    "    trxndf.sort_values([\"posted_date\"])\n",
    "      .drop_duplicates(subset=[\"prism_transaction_id\"], keep=\"first\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0672de9e-96cd-4342-98dc-6bc4b751b5e1",
   "metadata": {},
   "source": [
    "## scoring exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1fd5e680-d71f-44ee-9b76-85f76be7adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounts: how many accounts + how many balance snapshots\n",
    "acct_stats = (\n",
    "    acctdf.groupby(\"prism_consumer_id\")\n",
    "    .agg(\n",
    "        n_accounts=(\"prism_account_id\", \"nunique\"),\n",
    "        n_balance_days=(\"balance_date\", \"nunique\"),\n",
    "        first_balance=(\"balance_date\", \"min\"),\n",
    "        last_balance=(\"balance_date\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Transactions: count + span + credits\n",
    "tx_stats = (\n",
    "    trxndf.groupby(\"prism_consumer_id\")\n",
    "    .agg(\n",
    "        n_txn=(\"prism_transaction_id\", \"count\"),\n",
    "        first_txn=(\"posted_date\", \"min\"),\n",
    "        last_txn=(\"posted_date\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "tx_stats[\"txn_span_days\"] = (tx_stats[\"last_txn\"] - tx_stats[\"first_txn\"]).dt.days\n",
    "\n",
    "credit_stats = (\n",
    "    trxndf.assign(is_credit=(trxndf[\"credit_or_debit\"] == \"CREDIT\").astype(int))\n",
    "    .groupby(\"prism_consumer_id\")\n",
    "    .agg(n_credit=(\"is_credit\", \"sum\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Combine into one scoring table (one row per consumer)\n",
    "scoring = (\n",
    "    consdf[[\"prism_consumer_id\", \"evaluation_date\", \"DQ_TARGET\", \"credit_score\"]]\n",
    "    .merge(acct_stats, on=\"prism_consumer_id\", how=\"left\")\n",
    "    .merge(tx_stats, on=\"prism_consumer_id\", how=\"left\")\n",
    "    .merge(credit_stats, on=\"prism_consumer_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Fill missing stats with 0 where appropriate\n",
    "for col in [\"n_accounts\", \"n_balance_days\", \"n_txn\", \"txn_span_days\", \"n_credit\"]:\n",
    "    if col in scoring.columns:\n",
    "        scoring[col] = scoring[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d90ff634-6df9-4f9f-ad8f-bd6f95e7f878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>evaluation_date</th>\n",
       "      <th>DQ_TARGET</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>n_accounts</th>\n",
       "      <th>n_balance_days</th>\n",
       "      <th>first_balance</th>\n",
       "      <th>last_balance</th>\n",
       "      <th>n_txn</th>\n",
       "      <th>first_txn</th>\n",
       "      <th>last_txn</th>\n",
       "      <th>txn_span_days</th>\n",
       "      <th>n_credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>408.0</td>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>2021-09-11</td>\n",
       "      <td>179.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>314.0</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>180.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>448.0</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>180.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>271.0</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>180.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>306.0</td>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>2021-06-21</td>\n",
       "      <td>337.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prism_consumer_id evaluation_date  DQ_TARGET  credit_score  n_accounts  \\\n",
       "0                 0      2021-09-01          0         726.0         2.0   \n",
       "1                 1      2021-07-01          0         626.0         2.0   \n",
       "2                 2      2021-05-01          0         680.0         2.0   \n",
       "3                 3      2021-03-01          0         734.0         2.0   \n",
       "4                 4      2021-10-01          0         676.0         2.0   \n",
       "\n",
       "   n_balance_days first_balance last_balance  n_txn  first_txn   last_txn  \\\n",
       "0             1.0    2021-08-31   2021-08-31  408.0 2021-03-16 2021-09-11   \n",
       "1             1.0    2021-06-30   2021-06-30  314.0 2021-01-15 2021-07-14   \n",
       "2             1.0    2021-04-30   2021-04-30  448.0 2020-11-04 2021-05-03   \n",
       "3             1.0    2021-02-28   2021-02-28  271.0 2020-09-23 2021-03-22   \n",
       "4             2.0    2020-12-31   2021-09-30  306.0 2020-07-19 2021-06-21   \n",
       "\n",
       "   txn_span_days  n_credit  \n",
       "0          179.0      38.0  \n",
       "1          180.0      71.0  \n",
       "2          180.0      81.0  \n",
       "3          180.0      51.0  \n",
       "4          337.0      40.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d8bb9c86-de94-4263-924d-fc25b8332de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total consumers: 12000\n",
      "Consumers with NO accounts: 1592\n"
     ]
    }
   ],
   "source": [
    "# consumers with no accounts\n",
    "consumers_with_accounts = set(acctdf[\"prism_consumer_id\"].unique())\n",
    "all_consumers = set(consdf[\"prism_consumer_id\"].unique())\n",
    "\n",
    "no_account_ids = list(all_consumers - consumers_with_accounts)\n",
    "\n",
    "print(\"Total consumers:\", len(all_consumers))\n",
    "print(\"Consumers with NO accounts:\", len(no_account_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa7aaab7-70d1-4ce7-b743-b371888a9b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13266666666666665"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1592/12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e0279e1b-f378-498b-ab7b-db522875900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consumers with NO accounts but WITH transactions: 1479\n",
      "Total transaction rows for these consumers: 961436\n",
      "\n",
      "Example consumer IDs (no account but with transactions):\n",
      "['1706', '3327', '2042', '1970', '114']\n",
      "\n",
      "Sample transaction rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>prism_transaction_id</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>credit_or_debit</th>\n",
       "      <th>posted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>858236</th>\n",
       "      <td>1706</td>\n",
       "      <td>857660</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895947</th>\n",
       "      <td>3327</td>\n",
       "      <td>895260</td>\n",
       "      <td>0</td>\n",
       "      <td>300.00</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895953</th>\n",
       "      <td>3327</td>\n",
       "      <td>895266</td>\n",
       "      <td>0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2020-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895954</th>\n",
       "      <td>3327</td>\n",
       "      <td>895267</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2020-11-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728042</th>\n",
       "      <td>2042</td>\n",
       "      <td>727489</td>\n",
       "      <td>2</td>\n",
       "      <td>500.00</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2020-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858237</th>\n",
       "      <td>1706</td>\n",
       "      <td>857661</td>\n",
       "      <td>1</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>2020-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728043</th>\n",
       "      <td>2042</td>\n",
       "      <td>727490</td>\n",
       "      <td>4</td>\n",
       "      <td>25.00</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2020-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728044</th>\n",
       "      <td>2042</td>\n",
       "      <td>727491</td>\n",
       "      <td>2</td>\n",
       "      <td>500.00</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2020-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728045</th>\n",
       "      <td>2042</td>\n",
       "      <td>727492</td>\n",
       "      <td>4</td>\n",
       "      <td>475.00</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2020-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88530</th>\n",
       "      <td>1970</td>\n",
       "      <td>88466</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>CREDIT</td>\n",
       "      <td>2020-11-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prism_consumer_id prism_transaction_id  category   amount  \\\n",
       "858236              1706               857660         0  2000.00   \n",
       "895947              3327               895260         0   300.00   \n",
       "895953              3327               895266         0   200.00   \n",
       "895954              3327               895267         0   100.00   \n",
       "728042              2042               727489         2   500.00   \n",
       "858237              1706               857661         1  5000.00   \n",
       "728043              2042               727490         4    25.00   \n",
       "728044              2042               727491         2   500.00   \n",
       "728045              2042               727492         4   475.00   \n",
       "88530               1970                88466         4     0.05   \n",
       "\n",
       "       credit_or_debit posted_date  \n",
       "858236           DEBIT  2020-11-01  \n",
       "895947          CREDIT  2020-11-01  \n",
       "895953           DEBIT  2020-11-02  \n",
       "895954           DEBIT  2020-11-06  \n",
       "728042          CREDIT  2020-11-12  \n",
       "858237           DEBIT  2020-11-12  \n",
       "728043          CREDIT  2020-11-18  \n",
       "728044          CREDIT  2020-11-18  \n",
       "728045          CREDIT  2020-11-19  \n",
       "88530           CREDIT  2020-11-20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking to see how many \"no accounts\" have transactions\n",
    "trx_no_account = trxndf[trxndf[\"prism_consumer_id\"].isin(no_account_ids)]\n",
    "\n",
    "consumers_no_account_with_txn = trx_no_account[\"prism_consumer_id\"].nunique()\n",
    "\n",
    "print(\"\\nConsumers with NO accounts but WITH transactions:\", consumers_no_account_with_txn)\n",
    "\n",
    "\n",
    "# 3️⃣ Total transaction rows for these consumers\n",
    "print(\"Total transaction rows for these consumers:\", trx_no_account.shape[0])\n",
    "\n",
    "\n",
    "# 4️⃣ Show example consumer IDs\n",
    "print(\"\\nExample consumer IDs (no account but with transactions):\")\n",
    "print(list(trx_no_account[\"prism_consumer_id\"].unique())[:5])\n",
    "\n",
    "\n",
    "# 5️⃣ Show sample transaction rows\n",
    "print(\"\\nSample transaction rows:\")\n",
    "display(trx_no_account.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5574dfdb-f00c-4a77-8898-9fd3e8d1d927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12000.000000\n",
       "mean       427.969500\n",
       "std        393.403508\n",
       "min          0.000000\n",
       "25%        155.000000\n",
       "50%        337.000000\n",
       "75%        594.250000\n",
       "max       8478.000000\n",
       "Name: n_txn, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring[\"n_txn\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3356d64e-4d80-48aa-ba62-c88b411dfeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12000.000000\n",
       "mean       153.381167\n",
       "std         78.184482\n",
       "min          0.000000\n",
       "25%         88.000000\n",
       "50%        178.000000\n",
       "75%        242.000000\n",
       "max        801.000000\n",
       "Name: txn_span_days, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring[\"txn_span_days\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78503c-439d-4101-8334-b0302ad3c878",
   "metadata": {},
   "source": [
    "even the low activity consumers have 88 days (2-3 months) of transaction history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ceb13405-467e-4fda-b84b-71f2acec6873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12000.000000\n",
       "mean        73.214583\n",
       "std         76.819153\n",
       "min          0.000000\n",
       "25%         28.000000\n",
       "50%         52.000000\n",
       "75%         93.000000\n",
       "max       1553.000000\n",
       "Name: n_credit, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring[\"n_credit\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f034b5-158b-4de6-9590-59eca36638b4",
   "metadata": {},
   "source": [
    "bottom 25% has 28 credit transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11d058ae-13e3-4ef3-afe6-1ca20c12ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total consumers: 12000\n",
      "Excluded: 898\n",
      "Eligible: 11102\n",
      "Exclusion rate: 0.07483333333333334\n"
     ]
    }
   ],
   "source": [
    "RULES = {\n",
    "    \"no_accounts_and_no_transactions\": \n",
    "    (scoring[\"n_accounts\"] < 1) & (scoring[\"n_txn\"] < 1),\n",
    "\n",
    "    # short behavioral history (less than 30 days)\n",
    "    \"short_txn_history\": scoring[\"txn_span_days\"] < 30,\n",
    "}\n",
    "\n",
    "# store reasons\n",
    "for name, mask in RULES.items():\n",
    "    scoring[name] = mask\n",
    "\n",
    "# Exclusion flag\n",
    "scoring[\"excluded\"] = scoring[list(RULES.keys())].any(axis=1)\n",
    "\n",
    "# Summary\n",
    "print(\"Total consumers:\", scoring.shape[0])\n",
    "print(\"Excluded:\", scoring[\"excluded\"].sum())\n",
    "print(\"Eligible:\", (~scoring[\"excluded\"]).sum())\n",
    "print(\"Exclusion rate:\", scoring[\"excluded\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3b5fd47d-7f2d-4371-abfd-1159b91f2c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible consumers: 11102\n"
     ]
    }
   ],
   "source": [
    "eligible_ids = scoring.loc[~scoring[\"excluded\"], \"prism_consumer_id\"]\n",
    "\n",
    "print(\"Eligible consumers:\", len(eligible_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "71bd46e1-d9a4-42ad-a24a-1856678eae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "consdf_eligible = consdf[\n",
    "    consdf[\"prism_consumer_id\"].isin(eligible_ids)\n",
    "].copy()\n",
    "\n",
    "acctdf_eligible = acctdf[\n",
    "    acctdf[\"prism_consumer_id\"].isin(eligible_ids)\n",
    "].copy()\n",
    "\n",
    "trxndf_eligible = trxndf[\n",
    "    trxndf[\"prism_consumer_id\"].isin(eligible_ids)\n",
    "].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b5363ee4-5642-4b5b-9851-95ecdf939e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumers in consdf_eligible: 11102\n",
      "Consumers in acctdf_eligible: 9659\n",
      "Consumers in trxndf_eligible: 11102\n"
     ]
    }
   ],
   "source": [
    "print(\"Consumers in consdf_eligible:\", consdf_eligible[\"prism_consumer_id\"].nunique())\n",
    "print(\"Consumers in acctdf_eligible:\", acctdf_eligible[\"prism_consumer_id\"].nunique())\n",
    "print(\"Consumers in trxndf_eligible:\", trxndf_eligible[\"prism_consumer_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56d3756c-c98f-44ab-9d83-63d4486de146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consdf = consdf_eligible\n",
    "# acctdf = acctdf_eligible\n",
    "# trxndf = trxndf_eligible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13e105-ef3f-4c7c-9b5d-bfcf865d78a0",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "922b8766-35b8-40b2-aa84-93eee379df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = (\n",
    "    acctdf\n",
    "    .merge(consdf, on='prism_consumer_id', how='inner')\n",
    "    .groupby(['prism_consumer_id'])\n",
    "    .agg(\n",
    "        balance=('balance', 'sum'),\n",
    "        balance_date=('balance_date', 'max')\n",
    "    )\n",
    "    .reset_index()\n",
    ").merge(trxndf,on='prism_consumer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7ee8cc77-eedc-4268-b494-6a5e5e3d4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(cat_map[\"category_id\"], cat_map[\"category\"]))\n",
    "initial_df[\"category\"] = initial_df[\"category\"].replace(mapping)\n",
    "monthly_summary=initial_df.copy()\n",
    "monthly_summary['amount'] = np.where(initial_df['credit_or_debit'] == 'DEBIT', -initial_df['amount'],initial_df['amount'])\n",
    "monthly_summary['posted_date'] = pd.to_datetime(monthly_summary['posted_date'])\n",
    "monthly_summary = (\n",
    "    monthly_summary\n",
    "    .groupby(['prism_consumer_id', monthly_summary['posted_date'].dt.to_period('M')])\n",
    "    .agg(\n",
    "        starting_balance=('balance', 'first'),\n",
    "        monthly_total=('balance', 'sum'),\n",
    "        trxndf_count = ('balance', 'count')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "monthly_summary['posted_date'] = monthly_summary['posted_date'].dt.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4fc406db-5d5d-4ca3-b856-ec24af7bdf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_summary = monthly_summary.merge(consdf[['prism_consumer_id','DQ_TARGET']],on='prism_consumer_id').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b795d47d-2769-41e8-9dd1-24d88014de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure date type\n",
    "monthly_summary[\"posted_date\"] = pd.to_datetime(monthly_summary[\"posted_date\"])\n",
    "\n",
    "# sort properly\n",
    "monthly_summary = monthly_summary.sort_values([\"prism_consumer_id\", \"posted_date\"])\n",
    "\n",
    "# calculate running balance\n",
    "monthly_summary[\"monthly_balance\"] = (\n",
    "    monthly_summary[\"starting_balance\"]\n",
    "    + monthly_summary.groupby(\"prism_consumer_id\")[\"monthly_total\"].cumsum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c17c38a9-9814-453e-a518-cee201ba2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_df = monthly_summary[monthly_summary['DQ_TARGET'] == 1]\n",
    "nondel_df = monthly_summary[monthly_summary['DQ_TARGET'] == 0]\n",
    "ids_1 = del_df[\"prism_consumer_id\"].dropna().unique()\n",
    "ids_0 = del_df[\"prism_consumer_id\"].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8f7f42e8-3116-4b73-a117-1bfaa24212a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtotal_df = monthly_summary.groupby('prism_consumer_id').agg(\n",
    "        DQ_TARGET = ('DQ_TARGET', 'first'),\n",
    "        monthly_mean=('monthly_total', 'mean'),\n",
    "        monthly_max=('monthly_total', 'max'),\n",
    "        monthly_min=('monthly_total', 'min'),\n",
    "        trxndf_count = ('trxndf_count','first'),\n",
    "        month_count=('monthly_total', 'count')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7219c6da-935e-41a2-a4ce-ab0aced11450",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_df = initial_df[['prism_consumer_id','amount','credit_or_debit']].groupby(['prism_consumer_id','credit_or_debit']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92c7f3f1-a3f0-42a7-81bf-528d76f024e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_df = (\n",
    "    cd_df\n",
    "    .pivot_table(\n",
    "        index='prism_consumer_id',\n",
    "        columns='credit_or_debit',\n",
    "        values='amount',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    .assign(\n",
    "        credit_debit_ratio=lambda x: x['CREDIT'] / (x['DEBIT'] + 1),\n",
    "        net_flow=lambda x: x['CREDIT'] - x['DEBIT']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2da181ed-bc0c-44cb-979c-e903d18e26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_df = cd_df.reset_index().merge(consdf[['prism_consumer_id','DQ_TARGET']],on='prism_consumer_id').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "af7b2478-3526-42a0-bdbe-4c651f11c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_df = initial_df[['prism_consumer_id','posted_date','category','credit_or_debit','amount']].copy()\n",
    "net_df['amount'] = np.where(net_df['credit_or_debit'] == 'DEBIT', -net_df['amount'],net_df['amount'])\n",
    "net_df['posted_date'] = pd.to_datetime(net_df['posted_date'])\n",
    "net_df['month'] = net_df['posted_date'].dt.to_period('M')\n",
    "mn_df = net_df.groupby(['prism_consumer_id','month']).agg(\n",
    "        monthly_total=('amount', 'sum'),\n",
    "        monthly_std =('amount','std')\n",
    "    ).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02471de-3bff-4f4b-a5c4-d8d76a35e9b5",
   "metadata": {},
   "source": [
    "monthly features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9a50f43d-5ebe-4482-bdbc-e09ec5a093c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_features = mn_df.groupby(['prism_consumer_id']).agg(\n",
    "    monthly_net_total=('monthly_total', 'sum'),\n",
    "    monthly_net_avg=('monthly_total', 'mean'),\n",
    "    monthly_net_max=('monthly_total', 'max'),\n",
    "    monthly_net_min=('monthly_total', 'min'),\n",
    "    monthly_std_avg=('monthly_std', 'mean')\n",
    ").reset_index().merge(consdf[['prism_consumer_id','DQ_TARGET']],on='prism_consumer_id').dropna()\n",
    "monthly_features['prism_consumer_id'] = monthly_features['prism_consumer_id'].astype(int)\n",
    "mtotal_df = mtotal_df.reset_index()\n",
    "mtotal_df['prism_consumer_id'] = mtotal_df['prism_consumer_id'].astype(int)\n",
    "cd_df['prism_consumer_id'] = cd_df['prism_consumer_id'].astype(int)\n",
    "monthly_features['net_range'] = monthly_features['monthly_net_max'] - monthly_features['monthly_net_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3888caf2-ba4c-4b5e-8fec-d733bfafb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df['amount'] = np.where(initial_df['credit_or_debit'] == 'DEBIT', -initial_df['amount'],initial_df['amount'])\n",
    "cat_df = initial_df.groupby(['prism_consumer_id','category'])['amount'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "701d8a68-2f02-4531-9a88-06fadafc3c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pivot = (\n",
    "    cat_df\n",
    "    .pivot(\n",
    "        index='prism_consumer_id',\n",
    "        columns='category',\n",
    "        values='amount'\n",
    "    )\n",
    "    .fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2a2d6d34-0199-432b-b08b-e25990710365",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflows = cat_pivot.clip(upper=0).abs()\n",
    "inflows  = cat_pivot.clip(lower=0)\n",
    "\n",
    "cat_features = pd.DataFrame(index=cat_pivot.index)\n",
    "\n",
    "cat_features['total_outflows'] = outflows.sum(axis=1)\n",
    "cat_features['total_inflows']  = inflows.sum(axis=1)\n",
    "cat_features['net_flow']       = cat_pivot.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "17bb1ff7-2d68-42b7-861e-fec899de6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in outflows.columns:\n",
    "    cat_features[f'{col}_outflow_ratio'] = (\n",
    "        outflows[col] / (cat_features['total_outflows'] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f02f5b2-8110-4f07-a29d-7f6c77e6270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income reliance\n",
    "cat_features['paycheck_ratio'] = (\n",
    "    inflows.get('PAYCHECK', 0) / (cat_features['total_inflows'] + 1)\n",
    ")\n",
    "\n",
    "# Cash usage\n",
    "cat_features['atm_cash_ratio'] = (\n",
    "    outflows.get('ATM_CASH', 0) / (cat_features['total_outflows'] + 1)\n",
    ")\n",
    "\n",
    "# Entertainment vs essentials proxy\n",
    "cat_features['entertainment_ratio'] = (\n",
    "    outflows.get('ENTERTAINMENT', 0) / (cat_features['total_outflows'] + 1)\n",
    ")\n",
    "\n",
    "# Refund dependence\n",
    "cat_features['refund_ratio'] = (\n",
    "    inflows.get('REFUND', 0) / (cat_features['total_inflows'] + 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f4a14641-0206-4dcb-a786-24f98a338be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflows = outflows.reset_index().merge(consdf[['prism_consumer_id','DQ_TARGET']],on='prism_consumer_id').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c88a4ffa-2ad3-4d68-abf4-204cf818d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = cat_features.reset_index().merge(consdf[['prism_consumer_id','DQ_TARGET']],on='prism_consumer_id').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "35c159cd-6fd9-4fc9-8ee3-e9283bff64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = cat_features[['prism_consumer_id','refund_ratio','paycheck_ratio']].copy()\n",
    "add_df['prism_consumer_id'] = add_df['prism_consumer_id'].astype(int)\n",
    "outflows['prism_consumer_id'] = outflows['prism_consumer_id'].astype(int)\n",
    "out_df = outflows.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3634709e-6519-4921-bbe3-b82c4fa3851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df['amount'] = np.where(initial_df['credit_or_debit'] == 'DEBIT', -initial_df['amount'],initial_df['amount'])\n",
    "cat_df = initial_df.groupby(['prism_consumer_id','category'])['amount'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8162cccb-48dd-4519-9d6f-5ae21e2b9d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pivot = (\n",
    "    cat_df\n",
    "    .pivot(\n",
    "        index='prism_consumer_id',\n",
    "        columns='category',\n",
    "        values='amount'\n",
    "    )\n",
    "    .fillna(0)\n",
    ")\n",
    "cat_pivot.columns = cat_pivot.columns + \"_trxnavg\"\n",
    "cat_pivot = cat_pivot.reset_index().merge(consdf[['prism_consumer_id','DQ_TARGET']],on='prism_consumer_id').dropna()\n",
    "cat_pivot['prism_consumer_id'] = cat_pivot['prism_consumer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91937ee8-bf01-4fef-b2a8-85dc8795e880",
   "metadata": {},
   "source": [
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5e55c16a-59b2-4db3-92b5-4cc7b9534b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(cat_map[\"category_id\"], cat_map[\"category\"]))\n",
    "trxndf[\"category\"] = trxndf[\"category\"].replace(mapping)\n",
    "\n",
    "income_categories = [\n",
    "    'PAYCHECK',\n",
    "    'DEPOSIT',\n",
    "    'UNEMPLOYMENT_BENEFITS',\n",
    "    'OTHER_BENEFITS',\n",
    "    'PENSION',\n",
    "    'INVESTMENT_INCOME'\n",
    "]\n",
    "\n",
    "income_df = trxndf[\n",
    "    trxndf['category'].isin(income_categories)\n",
    "].copy()\n",
    "income_df['prism_transaction_id'].duplicated().sum()\n",
    "income_df['posted_date'] = pd.to_datetime(income_df['posted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7f8c1370-948d-4142-ab7a-70c2e8e4ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_time = (\n",
    "    income_df\n",
    "    .groupby('prism_consumer_id')\n",
    "    .agg(\n",
    "        first_income_date=('posted_date', 'min'),\n",
    "        last_income_date=('posted_date', 'max')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "income_time['income_span_days'] = (\n",
    "    income_time['last_income_date'] - income_time['first_income_date']\n",
    ").dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "11c67ab7-80ad-4e31-ac48-9603b714ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2257/1562562249.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  income_df['prism_consumer_id'] = income_time['prism_consumer_id'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "income_df = income_time[['prism_consumer_id','income_span_days']]\n",
    "income_df['prism_consumer_id'] = income_time['prism_consumer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8dc36-4e43-4f36-b070-8f0db25f4c13",
   "metadata": {},
   "source": [
    "preliminary testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e8654e72-16bd-450e-b4e4-5deab5efcdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pivot= cat_pivot.drop(columns='DQ_TARGET')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eedaa45d-bbd3-47ff-91e4-8624106f25e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prism_consumer_id</th>\n",
       "      <th>monthly_net_total</th>\n",
       "      <th>monthly_net_avg</th>\n",
       "      <th>monthly_net_max</th>\n",
       "      <th>monthly_net_min</th>\n",
       "      <th>monthly_std_avg</th>\n",
       "      <th>net_range</th>\n",
       "      <th>monthly_mean</th>\n",
       "      <th>monthly_max</th>\n",
       "      <th>monthly_min</th>\n",
       "      <th>...</th>\n",
       "      <th>REFUND_trxnavg</th>\n",
       "      <th>RENT_trxnavg</th>\n",
       "      <th>RISK_CATCH_ALL_trxnavg</th>\n",
       "      <th>RTO_LTO_trxnavg</th>\n",
       "      <th>SELF_TRANSFER_trxnavg</th>\n",
       "      <th>TAX_trxnavg</th>\n",
       "      <th>TIME_OR_STUFF_trxnavg</th>\n",
       "      <th>TRANSPORATION_trxnavg</th>\n",
       "      <th>TRAVEL_trxnavg</th>\n",
       "      <th>UNEMPLOYMENT_BENEFITS_trxnavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-521.59</td>\n",
       "      <td>-74.512857</td>\n",
       "      <td>830.73</td>\n",
       "      <td>-2584.24</td>\n",
       "      <td>213.544425</td>\n",
       "      <td>3414.97</td>\n",
       "      <td>1.867299e+04</td>\n",
       "      <td>27231.45</td>\n",
       "      <td>8970.36</td>\n",
       "      <td>...</td>\n",
       "      <td>19.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.685652</td>\n",
       "      <td>867.840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>54.375000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1805.43</td>\n",
       "      <td>257.918571</td>\n",
       "      <td>1109.02</td>\n",
       "      <td>-940.73</td>\n",
       "      <td>292.763392</td>\n",
       "      <td>2049.75</td>\n",
       "      <td>1.481371e+05</td>\n",
       "      <td>208052.46</td>\n",
       "      <td>102375.02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.410256</td>\n",
       "      <td>1162.700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>-1190.04</td>\n",
       "      <td>-170.005714</td>\n",
       "      <td>431.40</td>\n",
       "      <td>-971.45</td>\n",
       "      <td>260.603079</td>\n",
       "      <td>1402.85</td>\n",
       "      <td>4.015226e+04</td>\n",
       "      <td>60169.52</td>\n",
       "      <td>19781.76</td>\n",
       "      <td>...</td>\n",
       "      <td>18.466000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.568750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>-4505.77</td>\n",
       "      <td>-750.961667</td>\n",
       "      <td>1276.72</td>\n",
       "      <td>-3332.81</td>\n",
       "      <td>832.186871</td>\n",
       "      <td>4609.53</td>\n",
       "      <td>5.399456e+04</td>\n",
       "      <td>63731.28</td>\n",
       "      <td>45142.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.468750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547.296667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>438.08</td>\n",
       "      <td>62.582857</td>\n",
       "      <td>2982.67</td>\n",
       "      <td>-2884.56</td>\n",
       "      <td>1223.790895</td>\n",
       "      <td>5867.23</td>\n",
       "      <td>2.871107e+03</td>\n",
       "      <td>3524.25</td>\n",
       "      <td>476.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>828.920370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589</th>\n",
       "      <td>995</td>\n",
       "      <td>21842.68</td>\n",
       "      <td>3120.382857</td>\n",
       "      <td>10212.74</td>\n",
       "      <td>-3244.20</td>\n",
       "      <td>1016.422674</td>\n",
       "      <td>13456.94</td>\n",
       "      <td>2.053630e+06</td>\n",
       "      <td>3162590.31</td>\n",
       "      <td>670852.49</td>\n",
       "      <td>...</td>\n",
       "      <td>1.463333</td>\n",
       "      <td>1134.158000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1250.937000</td>\n",
       "      <td>626.432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>996</td>\n",
       "      <td>26713.18</td>\n",
       "      <td>3816.168571</td>\n",
       "      <td>41464.50</td>\n",
       "      <td>-16811.41</td>\n",
       "      <td>2623.765971</td>\n",
       "      <td>58275.91</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.944444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3532.145542</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>493.909091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9591</th>\n",
       "      <td>997</td>\n",
       "      <td>-14899.66</td>\n",
       "      <td>-2128.522857</td>\n",
       "      <td>206.99</td>\n",
       "      <td>-3741.45</td>\n",
       "      <td>745.079512</td>\n",
       "      <td>3948.44</td>\n",
       "      <td>4.787867e+06</td>\n",
       "      <td>6756531.35</td>\n",
       "      <td>1404823.35</td>\n",
       "      <td>...</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>940.464154</td>\n",
       "      <td>2516.000</td>\n",
       "      <td>20.149683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9592</th>\n",
       "      <td>998</td>\n",
       "      <td>5507.73</td>\n",
       "      <td>786.818571</td>\n",
       "      <td>3359.83</td>\n",
       "      <td>-1022.35</td>\n",
       "      <td>537.836676</td>\n",
       "      <td>4382.18</td>\n",
       "      <td>7.987620e+05</td>\n",
       "      <td>1116887.94</td>\n",
       "      <td>275774.80</td>\n",
       "      <td>...</td>\n",
       "      <td>9.546429</td>\n",
       "      <td>231.316667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>759.527885</td>\n",
       "      <td>2991.340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>248.140000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9593</th>\n",
       "      <td>999</td>\n",
       "      <td>20.09</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>2227.77</td>\n",
       "      <td>-1845.26</td>\n",
       "      <td>177.971543</td>\n",
       "      <td>4073.03</td>\n",
       "      <td>1.939252e+05</td>\n",
       "      <td>351110.09</td>\n",
       "      <td>42491.03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.955000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.317083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>356.126667</td>\n",
       "      <td>90.790000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9594 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prism_consumer_id  monthly_net_total  monthly_net_avg  monthly_net_max  \\\n",
       "0                     0            -521.59       -74.512857           830.73   \n",
       "1                     1            1805.43       257.918571          1109.02   \n",
       "2                    10           -1190.04      -170.005714           431.40   \n",
       "3                   100           -4505.77      -750.961667          1276.72   \n",
       "4                  1000             438.08        62.582857          2982.67   \n",
       "...                 ...                ...              ...              ...   \n",
       "9589                995           21842.68      3120.382857         10212.74   \n",
       "9590                996           26713.18      3816.168571         41464.50   \n",
       "9591                997          -14899.66     -2128.522857           206.99   \n",
       "9592                998            5507.73       786.818571          3359.83   \n",
       "9593                999              20.09         2.870000          2227.77   \n",
       "\n",
       "      monthly_net_min  monthly_std_avg  net_range  monthly_mean  monthly_max  \\\n",
       "0            -2584.24       213.544425    3414.97  1.867299e+04     27231.45   \n",
       "1             -940.73       292.763392    2049.75  1.481371e+05    208052.46   \n",
       "2             -971.45       260.603079    1402.85  4.015226e+04     60169.52   \n",
       "3            -3332.81       832.186871    4609.53  5.399456e+04     63731.28   \n",
       "4            -2884.56      1223.790895    5867.23  2.871107e+03      3524.25   \n",
       "...               ...              ...        ...           ...          ...   \n",
       "9589         -3244.20      1016.422674   13456.94  2.053630e+06   3162590.31   \n",
       "9590        -16811.41      2623.765971   58275.91  0.000000e+00         0.00   \n",
       "9591         -3741.45       745.079512    3948.44  4.787867e+06   6756531.35   \n",
       "9592         -1022.35       537.836676    4382.18  7.987620e+05   1116887.94   \n",
       "9593         -1845.26       177.971543    4073.03  1.939252e+05    351110.09   \n",
       "\n",
       "      monthly_min  ...  REFUND_trxnavg  RENT_trxnavg  RISK_CATCH_ALL_trxnavg  \\\n",
       "0         8970.36  ...       19.960000      0.000000                     0.0   \n",
       "1       102375.02  ...        2.420000      0.000000                     0.0   \n",
       "2        19781.76  ...       18.466000    103.000000                     0.0   \n",
       "3        45142.99  ...        1.468750      0.000000                     0.0   \n",
       "4          476.25  ...        1.370000      0.000000                     0.0   \n",
       "...           ...  ...             ...           ...                     ...   \n",
       "9589    670852.49  ...        1.463333   1134.158000                     0.0   \n",
       "9590         0.00  ...        2.944444      0.000000                     0.0   \n",
       "9591   1404823.35  ...       14.420000      0.000000                     0.0   \n",
       "9592    275774.80  ...        9.546429    231.316667                     0.0   \n",
       "9593     42491.03  ...        4.955000     46.500000                     0.0   \n",
       "\n",
       "      RTO_LTO_trxnavg  SELF_TRANSFER_trxnavg  TAX_trxnavg  \\\n",
       "0                 0.0             116.685652      867.840   \n",
       "1                 0.0             233.410256     1162.700   \n",
       "2                 0.0             237.568750        0.000   \n",
       "3                 0.0             547.296667        0.000   \n",
       "4                 0.0             828.920370        0.000   \n",
       "...               ...                    ...          ...   \n",
       "9589              0.0            1250.937000      626.432   \n",
       "9590              0.0            3532.145542        0.000   \n",
       "9591              0.0             940.464154     2516.000   \n",
       "9592              0.0             759.527885     2991.340   \n",
       "9593              0.0              50.317083        0.000   \n",
       "\n",
       "      TIME_OR_STUFF_trxnavg  TRANSPORATION_trxnavg  TRAVEL_trxnavg  \\\n",
       "0                  0.000000               2.480000       54.375000   \n",
       "1                  0.000000              25.900000        0.000000   \n",
       "2                  0.000000              17.520000        0.000000   \n",
       "3                  0.000000               0.000000        0.000000   \n",
       "4                  0.000000               0.000000        0.000000   \n",
       "...                     ...                    ...             ...   \n",
       "9589               0.000000               0.000000        0.000000   \n",
       "9590               0.000000              12.000000      493.909091   \n",
       "9591              20.149683               0.000000        0.000000   \n",
       "9592               0.000000              12.700000      248.140000   \n",
       "9593               0.000000             356.126667       90.790000   \n",
       "\n",
       "      UNEMPLOYMENT_BENEFITS_trxnavg  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "...                             ...  \n",
       "9589                            0.0  \n",
       "9590                            0.0  \n",
       "9591                            0.0  \n",
       "9592                            0.0  \n",
       "9593                            0.0  \n",
       "\n",
       "[9594 rows x 114 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df= monthly_features.merge(mtotal_df,on='prism_consumer_id')\n",
    "main_df['DQ_TARGET'] = main_df['DQ_TARGET_x']\n",
    "main_df = main_df.drop(columns=['DQ_TARGET_x','DQ_TARGET_y'])\n",
    "cd_df = cd_df.drop(columns=['net_flow','DQ_TARGET'])\n",
    "main_df= main_df.merge(cd_df,on='prism_consumer_id')\n",
    "main_df= main_df.merge(add_df,on='prism_consumer_id')\n",
    "main_df= main_df.merge(out_df,on='prism_consumer_id')\n",
    "main_df= main_df.merge(income_df,on='prism_consumer_id')\n",
    "main_df= main_df.merge(cat_pivot,on='prism_consumer_id')\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eade2660-ec66-4d65-a9d0-546f448023ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns I will need: credit/debit, amount, posted date, evaluation date, prism consumer id, DQ_TARGET\n",
    "merged = pd.merge(consdf.dropna(), trxndf, on='prism_consumer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "38897407-34f2-4da7-8b87-9d431261cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[merged['posted_date'] <= merged['evaluation_date']]\n",
    "credit_only = merged[merged['credit_or_debit'] == 'CREDIT'].copy()\n",
    "credit_only['posted_date'] = pd.to_datetime(credit_only['posted_date'])\n",
    "credit_only['Year-Month'] = credit_only['posted_date'].dt.to_period('M')\n",
    "debt_only = trxndf[trxndf['credit_or_debit']=='DEBIT']\n",
    "monthly_inflow = credit_only.groupby(['prism_consumer_id', 'Year-Month'])['amount'].sum().reset_index(name='monthly_inflow')\n",
    "consdf['Evaluation Month'] = consdf['evaluation_date'].dt.to_period('M')\n",
    "with_eval_month = pd.merge(consdf, monthly_inflow, on='prism_consumer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e40741ff-1368-4c9d-9579-64ccca968bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_eval_month['months_diff'] = (\n",
    "    (with_eval_month['Evaluation Month'].dt.year - with_eval_month['Year-Month'].dt.year) * 12 +\n",
    "    (with_eval_month['Evaluation Month'].dt.month - with_eval_month['Year-Month'].dt.month)\n",
    ")\n",
    "last_year = with_eval_month[(with_eval_month['months_diff'] >= 1) & (with_eval_month['months_diff'] <= 12)]\n",
    "sum_yearly_inflow = last_year.groupby('prism_consumer_id')['monthly_inflow'].sum().reset_index(name='avg_yearly_inflow')\n",
    "year_std = last_year.groupby('prism_consumer_id')['monthly_inflow'].std().reset_index()\n",
    "year_std.columns = ['prism_consumer_id', 'std_inflow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bc4d2da7-e6a0-4989-9b47-9a02a38be66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend: Is income increasing or decreasing?\n",
    "def calculate_trend(group):\n",
    "    if len(group) < 2:\n",
    "        return 0\n",
    "    months = group['months_diff'].values\n",
    "    inflows = group['monthly_inflow'].values\n",
    "    return np.polyfit(months, inflows, 1)[0]  # slope\n",
    "\n",
    "trend = last_year.groupby('prism_consumer_id').apply(calculate_trend, include_groups=False).reset_index()\n",
    "trend.columns = ['prism_consumer_id', 'trend']\n",
    "num_transactions = last_year.groupby('prism_consumer_id').size().reset_index()\n",
    "num_transactions.columns = ['prism_consumer_id', 'num_transactions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "52a28c42-85d9-481a-ae25-8e990bc0aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_only = trxndf[trxndf['credit_or_debit'] == 'DEBIT'].copy()\n",
    "debt_only['posted_date'] = pd.to_datetime(debt_only['posted_date'])\n",
    "# debt_only['category'] = debt_only['category'].astype(int)\n",
    "\n",
    "# debt_with_category = pd.merge(debt_only, cat_map, left_on='category', right_on='category_id', how='left')[['prism_consumer_id',\\\n",
    "#     'prism_transaction_id', 'amount', 'credit_or_debit', 'posted_date', 'category_id', 'category_y']]\n",
    "debt_with_category = debt_only.rename(columns={'category_y':'category'})\n",
    "groceries_only = debt_with_category[debt_with_category['category']=='GROCERIES']\n",
    "\n",
    "debt_with_eval = pd.merge(groceries_only, consdf[['prism_consumer_id', 'evaluation_date']], on='prism_consumer_id', how='left')\n",
    "\n",
    "# Filter for transactions in the 3 months before evaluation_date\n",
    "debt_with_eval['months_before_eval'] = (\n",
    "    (debt_with_eval['evaluation_date'].dt.year - debt_with_eval['posted_date'].dt.year) * 12 +\n",
    "    (debt_with_eval['evaluation_date'].dt.month - debt_with_eval['posted_date'].dt.month)\n",
    ")\n",
    "\n",
    "debt_9m = debt_with_eval[(debt_with_eval['months_before_eval'] >= 0) & \n",
    "                          (debt_with_eval['months_before_eval'] < 9)]\n",
    "\n",
    "# total spend of groceries per consumer over a 9 month window (last 9 months before eval date)\n",
    "total_spend_groceries_9m = debt_9m.groupby('prism_consumer_id')['amount'].sum().reset_index()\n",
    "total_spend_groceries_9m.columns = ['prism_consumer_id', 'sum_groceries_9m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3882fa69-e026-4936-9f4e-827084fc3d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total spend of dining per consumer over a month window (last month before eval date)\n",
    "dining_only = debt_with_category[debt_with_category['category']=='FOOD_AND_BEVERAGES']\n",
    "\n",
    "debt_with_eval_dining = pd.merge(dining_only, consdf[['prism_consumer_id', 'evaluation_date']], on='prism_consumer_id', how='left')\n",
    "\n",
    "# Filter for transactions in the 6 months before evaluation_date\n",
    "debt_with_eval_dining['months_before_eval'] = (\n",
    "    (debt_with_eval_dining['evaluation_date'].dt.year - debt_with_eval_dining['posted_date'].dt.year) * 12 +\n",
    "    (debt_with_eval_dining['evaluation_date'].dt.month - debt_with_eval_dining['posted_date'].dt.month)\n",
    ")\n",
    "\n",
    "debt_6m = debt_with_eval_dining[(debt_with_eval_dining['months_before_eval'] >= 0) & \n",
    "                          (debt_with_eval_dining['months_before_eval'] < 6)]\n",
    "\n",
    "# total spend of groceries per consumer over a 6 month window (last 6 months before eval date)\n",
    "total_spend_dining_6m = debt_6m.groupby('prism_consumer_id')['amount'].sum().reset_index()\n",
    "total_spend_dining_6m.columns = ['prism_consumer_id', 'sum_dining_6m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "79c0f4c6-f2a5-4208-8894-7f3eadbf5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge evaluation date ONCE\n",
    "tx = debt_with_category.merge(\n",
    "    consdf[['prism_consumer_id', 'evaluation_date']],\n",
    "    on='prism_consumer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "tx = tx[tx['credit_or_debit'] == 'DEBIT']\n",
    "tx['amount'] = tx['amount'].abs()\n",
    "\n",
    "# numerator\n",
    "total_spend_gambling = tx[tx['category'] == 'GAMBLING'].groupby('prism_consumer_id')['amount'].sum()\n",
    "\n",
    "# denominator\n",
    "total_spend_all = tx.groupby('prism_consumer_id')['amount'].sum()\n",
    "\n",
    "pct_spend_gambling = (total_spend_gambling / total_spend_all).fillna(0).reset_index(name='pct_spend_gambling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "10fc160c-7eec-4d1d-93b3-e365763d28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "essentials = ['RENT', 'MORTGAGE', 'BILLS_UTILITIES', 'ESSENTIAL_SERVICES', 'GROCERIES', 'AUTOMOTIVE', 'TRANSPORTATION', \\\n",
    "'HEALTHCARE_MEDICAL', 'INSURANCE', 'CHILD_DEPENDENTS', 'PETS', 'TAX', 'LOAN', 'AUTO_LOAN', 'DEBT', 'CREDIT_CARD_PAYMENT', \\\n",
    "'EDUCATION', 'LEGAL', 'GOVERNMENT_SERVICES']\n",
    "\n",
    "total_spend_essentials = tx[tx['category'].isin(essentials)].groupby('prism_consumer_id')['amount'].sum()\n",
    "\n",
    "pct_spend_essentials = (total_spend_essentials / total_spend_all).reset_index()\n",
    "\n",
    "pct_spend_essentials = pct_spend_essentials.rename(columns={'amount':'pct_spend_essentials'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aa5bad24-1634-4277-bc47-41bf522c52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change in groceries per consumer from the 3 most recent months to the prior 3-6 months before evaluation date\n",
    "# lowers AUC from 0.721 to 0.71\n",
    "\n",
    "# recent 3 months (0–2)\n",
    "recent_3m = debt_with_eval[(debt_with_eval['months_before_eval'] >= 0) & (debt_with_eval['months_before_eval'] < 3)]\n",
    "\n",
    "recent_spend = recent_3m.groupby('prism_consumer_id')['amount'].sum().reset_index(name='groceries_0_3m')\n",
    "\n",
    "# prior 3 months (3–5)\n",
    "prior_3m = debt_with_eval[(debt_with_eval['months_before_eval'] >= 3) & (debt_with_eval['months_before_eval'] < 6)]\n",
    "\n",
    "prior_spend = prior_3m.groupby('prism_consumer_id')['amount'].sum().reset_index(name='groceries_3_6m')\n",
    "\n",
    "# merge and compute delta\n",
    "delta_groceries_3m = recent_spend.merge(\n",
    "    prior_spend,\n",
    "    on='prism_consumer_id',\n",
    "    how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "delta_groceries_3m['delta_groceries_3m'] = delta_groceries_3m['groceries_0_3m'] - delta_groceries_3m['groceries_3_6m']\n",
    "\n",
    "delta_groceries_3m = delta_groceries_3m[['prism_consumer_id', 'delta_groceries_3m']]\n",
    "\n",
    "utilities = ['BILLS_UTILITIES', 'ESSENTIAL_SERVICES']\n",
    "\n",
    "total_spend_utilities = tx[tx['category'].isin(utilities)].groupby('prism_consumer_id')['amount'].sum()\n",
    "\n",
    "pct_spend_utilities = (total_spend_utilities / total_spend_all).reset_index()\n",
    "\n",
    "pct_spend_utilities = pct_spend_utilities.rename(columns={'amount':'pct_spend_utilities'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c733466a-63f0-4898-8222-fbc8acf517be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# has overdraft - 6 months\n",
    "# Merge evaluation dates with ALL debt transactions\n",
    "debt_with_eval = pd.merge(\n",
    "    debt_with_category, \n",
    "    consdf[['prism_consumer_id', 'evaluation_date']], \n",
    "    on='prism_consumer_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate days before evaluation\n",
    "debt_with_eval['days_before_eval'] = (\n",
    "    debt_with_eval['evaluation_date'] - debt_with_eval['posted_date']\n",
    ").dt.days\n",
    "\n",
    "# Filter for OVERDRAFT category AND within 6 months\n",
    "overdraft_6m = debt_with_eval[\n",
    "    (debt_with_eval['category'] == 'OVERDRAFT') &\n",
    "    (debt_with_eval['days_before_eval'] >= 0) & \n",
    "    (debt_with_eval['days_before_eval'] <= 180)\n",
    "]\n",
    "\n",
    "# Group to get consumers with overdrafts\n",
    "has_overdraft_6m = overdraft_6m.groupby('prism_consumer_id').size().reset_index(name='overdraft_count')\n",
    "has_overdraft_6m['has_overdraft_6m'] = 1\n",
    "\n",
    "has_overdraft_6m = has_overdraft_6m[['prism_consumer_id', 'has_overdraft_6m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b925c9ab-a357-4393-8db5-84d65f8e769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# has account fees - 6 months\n",
    "# Merge evaluation dates with ALL debt transactions\n",
    "debt_with_eval = pd.merge(\n",
    "    debt_with_category, \n",
    "    consdf[['prism_consumer_id', 'evaluation_date']], \n",
    "    on='prism_consumer_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate days before evaluation\n",
    "debt_with_eval['days_before_eval'] = (\n",
    "    debt_with_eval['evaluation_date'] - debt_with_eval['posted_date']\n",
    ").dt.days\n",
    "\n",
    "# Filter for ACCOUNT FEES category AND within 6 months\n",
    "acct_fees_6m = debt_with_eval[\n",
    "    (debt_with_eval['category'] == 'ACCOUNT_FEES') &\n",
    "    (debt_with_eval['days_before_eval'] >= 0) & \n",
    "    (debt_with_eval['days_before_eval'] <= 180)\n",
    "]\n",
    "\n",
    "# Group to get consumers with acct fee\n",
    "has_acct_fee_6m = acct_fees_6m.groupby('prism_consumer_id').size().reset_index(name='acct_fees_count')\n",
    "has_acct_fee_6m['has_acct_fee_6m'] = 1\n",
    "\n",
    "has_acct_fee_6m = has_acct_fee_6m[['prism_consumer_id', 'has_acct_fee_6m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9496324f-d048-49a8-953c-517dcbb83678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#atm cash ratio per consumer\n",
    "\n",
    "debt_with_eval = pd.merge(\n",
    "    debt_with_category,\n",
    "    consdf[['prism_consumer_id', 'evaluation_date']],\n",
    "    on='prism_consumer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "debt_with_eval['posted_date'] = pd.to_datetime(debt_with_eval['posted_date'])\n",
    "debt_with_eval['evaluation_date'] = pd.to_datetime(debt_with_eval['evaluation_date'])\n",
    "\n",
    "debt_with_eval = debt_with_eval[\n",
    "    debt_with_eval['posted_date'] <= debt_with_eval['evaluation_date']\n",
    "]\n",
    "\n",
    "total_debt_spend = debt_with_eval.groupby('prism_consumer_id')['amount'].sum().reset_index(name='total_debit_spend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d4e68910-9238-4dfe-81e3-522eca094cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_cash_spend = (\n",
    "    debt_with_eval[debt_with_eval['category'] == 'ATM_CASH']\n",
    "    .groupby('prism_consumer_id')['amount']\n",
    "    .sum()\n",
    "    .reset_index(name='atm_cash_spend')\n",
    ")\n",
    "\n",
    "atm_cash_ratio = total_debt_spend.merge(atm_cash_spend, on='prism_consumer_id',how='left').fillna(0)\n",
    "atm_cash_ratio['atm_cash_ratio'] = atm_cash_ratio['atm_cash_spend'] / atm_cash_ratio['total_debit_spend']\n",
    "atm_cash_ratio['atm_cash_ratio'] = (\n",
    "    atm_cash_ratio['atm_cash_ratio']\n",
    "    .replace([np.inf, -np.inf], 0)\n",
    "    .fillna(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2d6300cc-9f59-4825-8a66-140be51f1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge evaluation dates with ALL debt transactions\n",
    "debt_with_eval = pd.merge(\n",
    "    debt_with_category, \n",
    "    consdf[['prism_consumer_id', 'evaluation_date']], \n",
    "    on='prism_consumer_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate days before evaluation\n",
    "debt_with_eval['days_before_eval'] = (\n",
    "    debt_with_eval['evaluation_date'] - debt_with_eval['posted_date']\n",
    ").dt.days\n",
    "\n",
    "atm_cash_freq_6m = acct_fees_6m.groupby('prism_consumer_id').size().reset_index(name='atm_cash_freq_6m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1e5dbebe-4b95-4306-a752-d491b05d18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refund ratio\n",
    "credit_only = trxndf[trxndf['credit_or_debit']=='CREDIT']\n",
    "# merged_credit = pd.merge(credit_only, cat_map, left_on='category', right_on='category_id', how='left')[['prism_consumer_id', 'prism_transaction_id', 'amount', \\\n",
    "# 'credit_or_debit', 'posted_date', 'category_id', 'category_y']]\n",
    "merged_credit = credit_only.rename(columns={'category_y': 'category'})\n",
    "\n",
    "credit_with_eval = pd.merge(\n",
    "    merged_credit,\n",
    "    consdf[['prism_consumer_id', 'evaluation_date']],\n",
    "    on='prism_consumer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "credit_with_eval['posted_date'] = pd.to_datetime(credit_with_eval['posted_date'])\n",
    "credit_with_eval['evaluation_date'] = pd.to_datetime(credit_with_eval['evaluation_date'])\n",
    "\n",
    "credit_with_eval['days_before_eval'] = (credit_with_eval['evaluation_date'] - credit_with_eval['posted_date']).dt.days\n",
    "window = credit_with_eval[(credit_with_eval['days_before_eval'] >= 0) & (credit_with_eval['days_before_eval'] <= 180)]\n",
    "\n",
    "refund = window[window['category']=='REFUND'].groupby('prism_consumer_id')['amount'].sum().reset_index(name='refund_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "557b681a-990e-448f-9ec8-5639180775b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "debit_only = trxndf[trxndf['credit_or_debit'] == 'DEBIT']\n",
    "# merged_debit = pd.merge(\n",
    "#     debit_only,\n",
    "#     cat_map,\n",
    "#     left_on='category',\n",
    "#     right_on='category_id',\n",
    "#     how='left'\n",
    "# )[[\n",
    "#     'prism_consumer_id',\n",
    "#     'prism_transaction_id',\n",
    "#     'amount',\n",
    "#     'credit_or_debit',\n",
    "#     'posted_date',\n",
    "#     'category_id',\n",
    "#     'category_y'\n",
    "# ]]\n",
    "\n",
    "merged_debit = debit_only.rename(columns={'category_y': 'category'})\n",
    "debit_with_eval = pd.merge(\n",
    "    merged_debit,\n",
    "    consdf[['prism_consumer_id', 'evaluation_date']],\n",
    "    on='prism_consumer_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "debit_with_eval['posted_date'] = pd.to_datetime(debit_with_eval['posted_date'])\n",
    "debit_with_eval['evaluation_date'] = pd.to_datetime(debit_with_eval['evaluation_date'])\n",
    "\n",
    "debit_with_eval['days_before_eval'] = (\n",
    "    debit_with_eval['evaluation_date'] - debit_with_eval['posted_date']\n",
    ").dt.days\n",
    "\n",
    "debit_window = debit_with_eval[\n",
    "    (debit_with_eval['days_before_eval'] >= 0) &\n",
    "    (debit_with_eval['days_before_eval'] <= 180)\n",
    "]\n",
    "\n",
    "debit_spend = debit_window[\n",
    "    debit_window['category'] != 'REFUND'\n",
    "]\n",
    "denominator = (\n",
    "    debit_spend\n",
    "    .groupby('prism_consumer_id')['amount']\n",
    "    .sum()\n",
    "    .reset_index(name='total_debit_spend')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6360ce0d-763d-4457-8b7f-ef33d756355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "refund_ratio = denominator.merge(\n",
    "    refund,\n",
    "    on='prism_consumer_id',\n",
    "    how='left'\n",
    ").fillna(0)\n",
    "\n",
    "refund_ratio['refund_ratio'] = (\n",
    "    refund_ratio['refund_amount'] /\n",
    "    refund_ratio['total_debit_spend']\n",
    ")\n",
    "\n",
    "refund_ratio['refund_ratio'] = (\n",
    "    refund_ratio['refund_ratio']\n",
    "    .replace([np.inf, -np.inf], 0)\n",
    "    .fillna(0)\n",
    ")\n",
    "refund_ratio = refund_ratio[['prism_consumer_id', 'refund_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dac132ca-e83f-4ff0-a9a4-19b30e7956b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debt_payment_ratio\n",
    "# (LOAN + CREDIT_CARD_PAYMENT + AUTO_LOAN + BNPL) / total_debit_spend\n",
    "categories_of_interest = ['LOAN', 'CREDIT_CARD_PAYMENT', 'AUTO_LOAN', 'BNPL']\n",
    "\n",
    "summary = (\n",
    "    debit_with_eval\n",
    "    .groupby('prism_consumer_id')\n",
    "    .agg(\n",
    "        total_debit_spend=('amount', 'sum'),\n",
    "        debt_spend=('amount', lambda x: x[\n",
    "            debit_with_eval.loc[x.index, 'category'].isin(categories_of_interest)\n",
    "        ].sum())\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary['debt_spend_ratio'] = summary['debt_spend'] / summary['total_debit_spend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ccb55ae8-2c61-4f9e-8237-630028bf1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bnpl usage flag\n",
    "# Filter for BNPL category AND within 6 months\n",
    "bnpl_usage_6m = debt_with_eval[\n",
    "    (debt_with_eval['category'] == 'BNPL') &\n",
    "    (debt_with_eval['days_before_eval'] >= 0) & \n",
    "    (debt_with_eval['days_before_eval'] <= 180)\n",
    "]\n",
    "\n",
    "# Group to get consumers with acct fee\n",
    "has_bnpl_usage_6m = bnpl_usage_6m.groupby('prism_consumer_id').size().reset_index(name='bnpl_usage_flag')\n",
    "has_bnpl_usage_6m['bnpl_usage_flag'] = 1\n",
    "\n",
    "has_bnpl_usage_6m = has_bnpl_usage_6m[['prism_consumer_id', 'bnpl_usage_flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cd5d02fc-514d-48d2-9788-500323199600",
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_categories = ['LOAN', 'CREDIT_CARD_PAYMENT', 'AUTO_LOAN', 'BNPL']\n",
    "\n",
    "debt_category_count = (\n",
    "    debit_with_eval[debit_with_eval['category'].isin(debt_categories)]\n",
    "    .groupby(['prism_consumer_id', 'category'])['amount']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# keep only categories with non-zero spend\n",
    "debt_category_count = debt_category_count[debt_category_count['amount'] != 0]\n",
    "\n",
    "debt_category_count = (\n",
    "    debt_category_count\n",
    "    .groupby('prism_consumer_id')\n",
    "    .size()\n",
    "    .reset_index(name='debt_category_count')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "da50e112-2449-41c6-bd3f-8980e1790aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretionary drop flag\n",
    "discretionary_cat_map = ['ENTERTAINMENT', 'TRAVEL', 'FITNESS']\n",
    "df = debit_with_eval.copy()\n",
    "df['month'] = df['posted_date'].dt.to_period('M')\n",
    "monthly_disc = df[df['category'].isin(discretionary_cat_map)].groupby(['prism_consumer_id', 'month'])['amount'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e7300d8b-9f9f-4225-acf7-050c61dfa4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "monthly_disc = monthly_disc.sort_values(['prism_consumer_id', 'month'])\n",
    "monthly_disc['disc_3m_spend'] = monthly_disc.groupby('prism_consumer_id')['amount'].rolling(3, min_periods=3).sum().reset_index(drop=True)\n",
    "monthly_disc['prev_disc_3m_spend'] = (\n",
    "    monthly_disc\n",
    "    .groupby('prism_consumer_id')['disc_3m_spend']\n",
    "    .shift(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3ab8dbb7-0fad-43c0-9d95-43db0c7b5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DROP_THRESHOLD = 0.30\n",
    "\n",
    "monthly_disc['discretionary_drop_flag_3m'] = (\n",
    "    (monthly_disc['prev_disc_3m_spend'] > 0) &\n",
    "    ((monthly_disc['prev_disc_3m_spend'] - monthly_disc['disc_3m_spend'])\n",
    "     / monthly_disc['prev_disc_3m_spend'] >= DROP_THRESHOLD)\n",
    ").astype(int)\n",
    "\n",
    "discretionary_drop_flag_3m = (\n",
    "    monthly_disc\n",
    "    .dropna(subset=['discretionary_drop_flag_3m'])\n",
    "    .groupby('prism_consumer_id')\n",
    "    .tail(1)\n",
    "    [['prism_consumer_id', 'discretionary_drop_flag_3m']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "044382e3-9bd0-4c1e-ad3e-7343054188c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essential spend volatility in 6 months\n",
    "# Filter for essentials AND within 6 months\n",
    "essential_spend_volatility_6m = debt_with_eval[\n",
    "    (debt_with_eval['category'].isin(essentials)) &\n",
    "    (debt_with_eval['days_before_eval'] >= 0) & \n",
    "    (debt_with_eval['days_before_eval'] <= 180)\n",
    "]\n",
    "\n",
    "# Group to get consumers with acct fee\n",
    "essential_spend_volatility_6m = essential_spend_volatility_6m.groupby('prism_consumer_id')['amount'].std().reset_index(name='essential_spend_volatility_6m')\n",
    "\n",
    "essential_spend_volatility_6m = essential_spend_volatility_6m[['prism_consumer_id', 'essential_spend_volatility_6m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e221ed8f-3501-4384-878d-0c530be00f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# child dependents spend sum in 6 months\n",
    "# Filter for child dependents AND within 6 months\n",
    "child_dependents_6m = debt_with_eval[\n",
    "    (debt_with_eval['category']=='CHILD_DEPENDENTS')&\n",
    "    (debt_with_eval['days_before_eval'] >= 0) & \n",
    "    (debt_with_eval['days_before_eval'] <= 180)\n",
    "]\n",
    "\n",
    "# Group to get consumers with child dependents\n",
    "has_child_deps_6m = bnpl_usage_6m.groupby('prism_consumer_id').size().reset_index(name='child_dependents_6m')\n",
    "has_child_deps_6m['child_dependents_6m'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8a76c59f-af3a-40b2-bf6a-6caddf8a428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# child dependents spend sum in 6 months\n",
    "# Filter for essentials AND within 6 months\n",
    "pets_6m = debt_with_eval[\n",
    "    (debt_with_eval['category']=='PETS')&\n",
    "    (debt_with_eval['days_before_eval'] >= 0) & \n",
    "    (debt_with_eval['days_before_eval'] <= 180)\n",
    "]\n",
    "\n",
    "# Group to get consumers with child dependents\n",
    "has_pets_6m = pets_6m.groupby('prism_consumer_id').size().reset_index(name='pets_6m')\n",
    "has_pets_6m['pets_6m'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5ffdb-44bc-4ef4-9080-147da86df304",
   "metadata": {},
   "source": [
    "## prepping model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "111701e2-af99-47db-be0f-9b59555e1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.merge(consdf, sum_yearly_inflow, on=\"prism_consumer_id\", how=\"left\")\n",
    "df_eval = pd.merge(df_eval, year_std, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, trend, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, num_transactions, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, total_spend_groceries_9m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, total_spend_dining_6m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, pct_spend_gambling, on='prism_consumer_id',how='left')\n",
    "df_eval = pd.merge(df_eval, pct_spend_essentials, on='prism_consumer_id',how='left')\n",
    "df_eval = pd.merge(df_eval, delta_groceries_3m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, pct_spend_utilities, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, has_overdraft_6m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, atm_cash_ratio, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, has_acct_fee_6m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, atm_cash_freq_6m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, refund_ratio, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, summary, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, has_bnpl_usage_6m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, debt_category_count, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, discretionary_drop_flag_3m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, essential_spend_volatility_6m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, has_child_deps_6m, on='prism_consumer_id', how='left')\n",
    "df_eval = pd.merge(df_eval, has_pets_6m, on='prism_consumer_id', how='left')\n",
    "df_eval['has_overdraft_6m'] = df_eval['has_overdraft_6m'].fillna(0).astype(int)\n",
    "df_eval['has_acct_fee_6m'] = df_eval['has_acct_fee_6m'].fillna(0).astype(int)\n",
    "df_eval['atm_cash_freq_6m'] = df_eval['atm_cash_freq_6m'].fillna(0).astype(int)\n",
    "df_eval['bnpl_usage_flag'] = df_eval['bnpl_usage_flag'].fillna(0).astype(int)\n",
    "df_eval['debt_category_count'] = df_eval['debt_category_count'].fillna(0).astype(int)\n",
    "df_eval['child_dependents_6m'] = df_eval['child_dependents_6m'].fillna(0).astype(int)\n",
    "df_eval['pets_6m'] = df_eval['pets_6m'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "83650b89-c508-4de4-b518-a09fc2e5c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval['prism_consumer_id'] =df_eval['prism_consumer_id'].astype(int)\n",
    "df_eval = main_df.merge(df_eval, on=\"prism_consumer_id\", how=\"right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "54247a19-b4d7-4ef1-915d-3e447ae280d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "period_cols = [col for col in df_eval.columns \n",
    "               if str(df_eval[col].dtype).startswith('period')]\n",
    "\n",
    "datetime_cols = df_eval.select_dtypes(include=['datetime64[ns]', 'datetimetz']).columns\n",
    "\n",
    "time_cols = list(datetime_cols) + period_cols\n",
    "df_eval = df_eval.drop(columns=time_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0ed80dcf-1520-4bf7-947c-1ddad6e83b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = df_eval.drop(columns=['DQ_TARGET_y','DQ_TARGET_x','credit_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b0fae6e7-eb35-46cc-b591-4deb7dfad801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_eval_master rows: 12000\n",
      "Excluded rows: 898\n",
      "Eligible rows: 11102\n"
     ]
    }
   ],
   "source": [
    "# --- dtype alignment for merge key ---\n",
    "df_eval = df_eval.copy()\n",
    "scoring_merge = scoring[[\"prism_consumer_id\", \"excluded\"]].copy()\n",
    "\n",
    "df_eval[\"prism_consumer_id\"] = df_eval[\"prism_consumer_id\"].astype(str)\n",
    "scoring_merge[\"prism_consumer_id\"] = scoring_merge[\"prism_consumer_id\"].astype(str)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Build master eval table with exclusion flag\n",
    "# --------------------------------------------\n",
    "df_eval_master = df_eval.merge(\n",
    "    scoring[[\"prism_consumer_id\", \"excluded\"]],\n",
    "    on=\"prism_consumer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# If a consumer didn't get a scoring row, treat them as excluded by default (conservative)\n",
    "df_eval_master[\"excluded\"] = df_eval_master[\"excluded\"].fillna(True)\n",
    "\n",
    "print(\"df_eval_master rows:\", df_eval_master.shape[0])\n",
    "print(\"Excluded rows:\", df_eval_master[\"excluded\"].sum())\n",
    "print(\"Eligible rows:\", (~df_eval_master[\"excluded\"]).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d5980b-cee2-46f2-a8c9-15fe99a21883",
   "metadata": {},
   "source": [
    "## model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "33fd6b06-7735-4830-a378-75e69f3e5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before exclusions: 12000\n",
      "Rows after exclusions : 11102\n",
      "\n",
      "==================== BEFORE EXCLUSIONS ====================\n",
      "Rows: 12000 | Pos rate: 0.08383333333333333\n",
      "\n",
      "Logistic Regression\n",
      "  train_auc: 0.7699 | test_auc: 0.7126\n",
      "  train_time: 22.8881s | score_time: 0.2932s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9523    0.6803    0.7936      2199\n",
      "           1     0.1520    0.6269    0.2447       201\n",
      "\n",
      "    accuracy                         0.6758      2400\n",
      "   macro avg     0.5521    0.6536    0.5191      2400\n",
      "weighted avg     0.8852    0.6758    0.7477      2400\n",
      "\n",
      "\n",
      "Random Forest\n",
      "  train_auc: 0.9981 | test_auc: 0.7419\n",
      "  train_time: 3.4935s | score_time: 0.3120s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9188    0.9627    0.9403      2199\n",
      "           1     0.1458    0.0697    0.0943       201\n",
      "\n",
      "    accuracy                         0.8879      2400\n",
      "   macro avg     0.5323    0.5162    0.5173      2400\n",
      "weighted avg     0.8541    0.8879    0.8694      2400\n",
      "\n",
      "\n",
      "XGBoost\n",
      "  train_auc: 0.9928 | test_auc: 0.7563\n",
      "  train_time: 2.8009s | score_time: 0.0501s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9204    0.9941    0.9558      2199\n",
      "           1     0.4800    0.0597    0.1062       201\n",
      "\n",
      "    accuracy                         0.9158      2400\n",
      "   macro avg     0.7002    0.5269    0.5310      2400\n",
      "weighted avg     0.8835    0.9158    0.8847      2400\n",
      "\n",
      "\n",
      "==================== AFTER EXCLUSIONS ====================\n",
      "Rows: 11102 | Pos rate: 0.08196721311475409\n",
      "\n",
      "Logistic Regression\n",
      "  train_auc: 0.7807 | test_auc: 0.7649\n",
      "  train_time: 16.6845s | score_time: 0.2897s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.6910    0.8061      2039\n",
      "           1     0.1754    0.7363    0.2833       182\n",
      "\n",
      "    accuracy                         0.6947      2221\n",
      "   macro avg     0.5712    0.7136    0.5447      2221\n",
      "weighted avg     0.9022    0.6947    0.7632      2221\n",
      "\n",
      "\n",
      "Random Forest\n",
      "  train_auc: 1.0000 | test_auc: 0.7869\n",
      "  train_time: 3.3183s | score_time: 0.2983s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9204    0.9985    0.9579      2039\n",
      "           1     0.6667    0.0330    0.0628       182\n",
      "\n",
      "    accuracy                         0.9194      2221\n",
      "   macro avg     0.7936    0.5157    0.5104      2221\n",
      "weighted avg     0.8996    0.9194    0.8845      2221\n",
      "\n",
      "\n",
      "XGBoost\n",
      "  train_auc: 0.9981 | test_auc: 0.7945\n",
      "  train_time: 2.8378s | score_time: 0.0473s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9233    0.9917    0.9563      2039\n",
      "           1     0.4516    0.0769    0.1315       182\n",
      "\n",
      "    accuracy                         0.9167      2221\n",
      "   macro avg     0.6875    0.5343    0.5439      2221\n",
      "weighted avg     0.8846    0.9167    0.8887      2221\n",
      "\n",
      "\n",
      "\n",
      "======== AUC SUMMARY (Before vs After) ========\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_auc_before</th>\n",
       "      <th>test_auc_before</th>\n",
       "      <th>train_time_before</th>\n",
       "      <th>score_time_before</th>\n",
       "      <th>train_auc_after</th>\n",
       "      <th>test_auc_after</th>\n",
       "      <th>train_time_after</th>\n",
       "      <th>score_time_after</th>\n",
       "      <th>delta_test_auc</th>\n",
       "      <th>delta_train_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.769939</td>\n",
       "      <td>0.712574</td>\n",
       "      <td>22.888135</td>\n",
       "      <td>0.293150</td>\n",
       "      <td>0.780743</td>\n",
       "      <td>0.764935</td>\n",
       "      <td>16.684540</td>\n",
       "      <td>0.289651</td>\n",
       "      <td>0.052361</td>\n",
       "      <td>0.010804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.998068</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>3.493538</td>\n",
       "      <td>0.312002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786926</td>\n",
       "      <td>3.318265</td>\n",
       "      <td>0.298348</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>0.001932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.992816</td>\n",
       "      <td>0.756280</td>\n",
       "      <td>2.800950</td>\n",
       "      <td>0.050140</td>\n",
       "      <td>0.998097</td>\n",
       "      <td>0.794529</td>\n",
       "      <td>2.837834</td>\n",
       "      <td>0.047273</td>\n",
       "      <td>0.038249</td>\n",
       "      <td>0.005281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  train_auc_before  test_auc_before  train_time_before  \\\n",
       "0  Logistic Regression          0.769939         0.712574          22.888135   \n",
       "1        Random Forest          0.998068         0.741935           3.493538   \n",
       "2              XGBoost          0.992816         0.756280           2.800950   \n",
       "\n",
       "   score_time_before  train_auc_after  test_auc_after  train_time_after  \\\n",
       "0           0.293150         0.780743        0.764935         16.684540   \n",
       "1           0.312002         1.000000        0.786926          3.318265   \n",
       "2           0.050140         0.998097        0.794529          2.837834   \n",
       "\n",
       "   score_time_after  delta_test_auc  delta_train_auc  \n",
       "0          0.289651        0.052361         0.010804  \n",
       "1          0.298348        0.044991         0.001932  \n",
       "2          0.047273        0.038249         0.005281  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# helper: evaluate one model\n",
    "# ----------------------------\n",
    "def eval_model_full(name, model, X_train, y_train, X_test, y_test, threshold=0.5):\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(X_train, y_train)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    # train probs + test probs\n",
    "    t2 = time.perf_counter()\n",
    "    ytr_prob = model.predict_proba(X_train)[:, 1]\n",
    "    yte_prob = model.predict_proba(X_test)[:, 1]\n",
    "    t3 = time.perf_counter()\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, ytr_prob)\n",
    "    test_auc  = roc_auc_score(y_test,  yte_prob)\n",
    "\n",
    "    # classification report at threshold\n",
    "    yte_pred = (yte_prob >= threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  train_auc: {train_auc:.4f} | test_auc: {test_auc:.4f}\")\n",
    "    print(f\"  train_time: {t1-t0:.4f}s | score_time: {t3-t2:.4f}s\")\n",
    "    print(classification_report(y_test, yte_pred, digits=4))\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"train_auc\": train_auc,\n",
    "        \"test_auc\": test_auc,\n",
    "        \"train_time\": t1 - t0,\n",
    "        \"score_time\": t3 - t2\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# common split function\n",
    "# ----------------------------\n",
    "def make_split(df, seed=42, test_size=0.2):\n",
    "    y = df[\"DQ_TARGET\"].astype(int)\n",
    "    X = df.drop(columns=[\"prism_consumer_id\", \"DQ_TARGET\"], errors=\"ignore\")\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=y, random_state=seed)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# define models (robust to NaNs)\n",
    "# ----------------------------\n",
    "logreg = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "rf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        max_depth=None\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"clf\", XGBClassifier(\n",
    "        n_estimators=600,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        eval_metric=\"auc\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "models = [\n",
    "    (\"Logistic Regression\", logreg),\n",
    "    (\"Random Forest\", rf),\n",
    "    (\"XGBoost\", xgb),\n",
    "]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# run comparison: before vs after\n",
    "# ----------------------------\n",
    "def run_suite(df, label, threshold=0.5):\n",
    "    X_train, X_test, y_train, y_test = make_split(df, seed=42, test_size=0.2)\n",
    "    results = []\n",
    "    print(f\"\\n==================== {label} ====================\")\n",
    "    print(\"Rows:\", df.shape[0], \"| Pos rate:\", df[\"DQ_TARGET\"].mean())\n",
    "    for name, model in models:\n",
    "        results.append(eval_model_full(name, model, X_train, y_train, X_test, y_test, threshold=threshold))\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# Build BEFORE/AFTER from df_eval_master\n",
    "# --------------------------------------------\n",
    "df_before = df_eval_master.drop(columns=[\"excluded\"]).copy()\n",
    "df_after  = df_eval_master.loc[~df_eval_master[\"excluded\"]].drop(columns=[\"excluded\"]).copy()\n",
    "\n",
    "print(\"Rows before exclusions:\", df_before.shape[0])\n",
    "print(\"Rows after exclusions :\", df_after.shape[0])\n",
    "\n",
    "res_before = run_suite(df_before, \"BEFORE EXCLUSIONS\", threshold=0.5)\n",
    "res_after  = run_suite(df_after,  \"AFTER EXCLUSIONS\",  threshold=0.5)\n",
    "\n",
    "summary = res_before.merge(res_after, on=\"model\", suffixes=(\"_before\", \"_after\"))\n",
    "summary[\"delta_test_auc\"]  = summary[\"test_auc_after\"]  - summary[\"test_auc_before\"]\n",
    "summary[\"delta_train_auc\"] = summary[\"train_auc_after\"] - summary[\"train_auc_before\"]\n",
    "\n",
    "print(\"\\n\\n======== AUC SUMMARY (Before vs After) ========\")\n",
    "display(summary.sort_values(\"delta_test_auc\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1864e64-cfd4-411b-bf03-7b599f6bc04f",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c994ebe1-b481-4336-9562-ae012c563e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "y = df_eval[\"DQ_TARGET\"].astype(int)\n",
    "\n",
    "# Features\n",
    "X = df_eval.drop(columns=[\"prism_consumer_id\", \"DQ_TARGET\"], errors=\"ignore\")\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "084d95ce-ade1-4743-ad98-7c39c1084851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features:\n",
      "month_count            0.081337\n",
      "num_transactions       0.064329\n",
      "monthly_max            0.015243\n",
      "CREDIT_CARD_PAYMENT    0.013678\n",
      "debt_category_count    0.013290\n",
      "monthly_min            0.012292\n",
      "monthly_mean           0.012073\n",
      "INSURANCE              0.010893\n",
      "has_overdraft_6m       0.010556\n",
      "refund_ratio_x         0.010434\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "selector_model = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "selector_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = pd.Series(\n",
    "    selector_model.feature_importances_,\n",
    "    index=X_train.columns\n",
    ")\n",
    "\n",
    "# Select top 50\n",
    "top_50 = importances.sort_values(ascending=False).head(50).index.tolist()\n",
    "\n",
    "print(\"Top 10 Features:\")\n",
    "print(importances.sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dbbf0a51-63db-46d1-90fe-7b6f34dcf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_50 = X_train[top_50]\n",
    "X_test_50  = X_test[top_50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "511cd26b-e956-466e-8091-2e054e199462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(name, model, Xtr, ytr, Xte, yte):\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(Xtr, ytr)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    ytr_prob = model.predict_proba(Xtr)[:, 1]\n",
    "    train_auc = roc_auc_score(ytr, ytr_prob)\n",
    "\n",
    "    t2 = time.perf_counter()\n",
    "    yte_prob = model.predict_proba(Xte)[:, 1]\n",
    "    t3 = time.perf_counter()\n",
    "\n",
    "    test_auc = roc_auc_score(yte, yte_prob)\n",
    "\n",
    "    y_pred = model.predict(Xte)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  Train AUC: {train_auc:.4f}\")\n",
    "    print(f\"  Test  AUC: {test_auc:.4f}\")\n",
    "    print(f\"  Overfit gap: {train_auc - test_auc:.4f}\")\n",
    "    print(f\"  Train time: {t1 - t0:.4f}s\")\n",
    "    print(f\"  Score time: {t3 - t2:.4f}s\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(yte, y_pred))\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"train_auc\": train_auc,\n",
    "        \"test_auc\": test_auc,\n",
    "        \"gap\": train_auc - test_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6678def7-8060-451a-9255-684a893443c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression (Top 50)\n",
      "  Train AUC: 0.7464\n",
      "  Test  AUC: 0.7016\n",
      "  Overfit gap: 0.0448\n",
      "  Train time: 7.6128s\n",
      "  Score time: 0.0003s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.63      0.76      2199\n",
      "           1       0.14      0.65      0.23       201\n",
      "\n",
      "    accuracy                           0.63      2400\n",
      "   macro avg       0.55      0.64      0.50      2400\n",
      "weighted avg       0.88      0.63      0.72      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_50)\n",
    "X_test_scaled  = scaler.transform(X_test_50)\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "res_log = eval_model(\n",
    "    \"Logistic Regression (Top 50)\",\n",
    "    logreg,\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    X_test_scaled,\n",
    "    y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "aebcfa57-7e33-410f-9144-50f5e506b036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (Top 50)\n",
      "  Train AUC: 0.9233\n",
      "  Test  AUC: 0.7501\n",
      "  Overfit gap: 0.1732\n",
      "  Train time: 1.5503s\n",
      "  Score time: 0.1326s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88      2199\n",
      "           1       0.19      0.46      0.27       201\n",
      "\n",
      "    accuracy                           0.79      2400\n",
      "   macro avg       0.57      0.64      0.57      2400\n",
      "weighted avg       0.88      0.79      0.83      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=8,              # limit depth to prevent overfit\n",
    "    min_samples_leaf=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "res_rf = eval_model(\n",
    "    \"Random Forest (Top 50)\",\n",
    "    rf,\n",
    "    X_train_50,\n",
    "    y_train,\n",
    "    X_test_50,\n",
    "    y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4605890b-d365-459c-89d8-731afa0e3275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost (Top 50)\n",
      "  Train AUC: 0.9425\n",
      "  Test  AUC: 0.7500\n",
      "  Overfit gap: 0.1925\n",
      "  Train time: 0.9087s\n",
      "  Score time: 0.0080s\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2199\n",
      "           1       0.55      0.05      0.10       201\n",
      "\n",
      "    accuracy                           0.92      2400\n",
      "   macro avg       0.74      0.53      0.53      2400\n",
      "weighted avg       0.89      0.92      0.88      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=4,              # shallower to reduce overfit\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.2,\n",
    "    reg_alpha=0.3,\n",
    "    reg_lambda=1.5,\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "res_xgb = eval_model(\n",
    "    \"XGBoost (Top 50)\",\n",
    "    xgb,\n",
    "    X_train_50,\n",
    "    y_train,\n",
    "    X_test_50,\n",
    "    y_test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6a5fa748-66f2-4a76-a88c-9a8bc93f7b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest (Top 50)</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.750083</td>\n",
       "      <td>0.173197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost (Top 50)</td>\n",
       "      <td>0.942460</td>\n",
       "      <td>0.750004</td>\n",
       "      <td>0.192456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (Top 50)</td>\n",
       "      <td>0.746394</td>\n",
       "      <td>0.701633</td>\n",
       "      <td>0.044761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  train_auc  test_auc       gap\n",
       "1        Random Forest (Top 50)   0.923280  0.750083  0.173197\n",
       "2              XGBoost (Top 50)   0.942460  0.750004  0.192456\n",
       "0  Logistic Regression (Top 50)   0.746394  0.701633  0.044761"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame([res_log, res_rf, res_xgb])\n",
    "results_df.sort_values(\"test_auc\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead49d6e-5a42-46a6-8e3a-9859dbaa4b0f",
   "metadata": {},
   "source": [
    "### summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e5f12412-87b4-423b-b3d9-d3df66c372ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== BEFORE exclusions | ALL features ====================\n",
      "Rows: 12000 | Pos rate: 0.08383333333333333 | Features: 137\n",
      "\n",
      "Logistic Regression\n",
      "  train_auc: 0.7699 | test_auc: 0.7126\n",
      "  train_time: 21.5427s | score_time: 0.1886s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9523    0.6803    0.7936      2199\n",
      "           1     0.1520    0.6269    0.2447       201\n",
      "\n",
      "    accuracy                         0.6758      2400\n",
      "   macro avg     0.5521    0.6536    0.5191      2400\n",
      "weighted avg     0.8852    0.6758    0.7477      2400\n",
      "\n",
      "\n",
      "Random Forest\n",
      "  train_auc: 0.9981 | test_auc: 0.7419\n",
      "  train_time: 3.4268s | score_time: 0.2873s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9188    0.9627    0.9403      2199\n",
      "           1     0.1458    0.0697    0.0943       201\n",
      "\n",
      "    accuracy                         0.8879      2400\n",
      "   macro avg     0.5323    0.5162    0.5173      2400\n",
      "weighted avg     0.8541    0.8879    0.8694      2400\n",
      "\n",
      "\n",
      "XGBoost\n",
      "  train_auc: 0.9928 | test_auc: 0.7563\n",
      "  train_time: 2.8713s | score_time: 0.0503s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9204    0.9941    0.9558      2199\n",
      "           1     0.4800    0.0597    0.1062       201\n",
      "\n",
      "    accuracy                         0.9158      2400\n",
      "   macro avg     0.7002    0.5269    0.5310      2400\n",
      "weighted avg     0.8835    0.9158    0.8847      2400\n",
      "\n",
      "\n",
      "==================== AFTER  exclusions | ALL features ====================\n",
      "Rows: 11102 | Pos rate: 0.08196721311475409 | Features: 137\n",
      "\n",
      "Logistic Regression\n",
      "  train_auc: 0.7807 | test_auc: 0.7649\n",
      "  train_time: 18.5027s | score_time: 0.3053s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.6910    0.8061      2039\n",
      "           1     0.1754    0.7363    0.2833       182\n",
      "\n",
      "    accuracy                         0.6947      2221\n",
      "   macro avg     0.5712    0.7136    0.5447      2221\n",
      "weighted avg     0.9022    0.6947    0.7632      2221\n",
      "\n",
      "\n",
      "Random Forest\n",
      "  train_auc: 1.0000 | test_auc: 0.7869\n",
      "  train_time: 3.3312s | score_time: 0.2816s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9204    0.9985    0.9579      2039\n",
      "           1     0.6667    0.0330    0.0628       182\n",
      "\n",
      "    accuracy                         0.9194      2221\n",
      "   macro avg     0.7936    0.5157    0.5104      2221\n",
      "weighted avg     0.8996    0.9194    0.8845      2221\n",
      "\n",
      "\n",
      "XGBoost\n",
      "  train_auc: 0.9981 | test_auc: 0.7945\n",
      "  train_time: 2.7888s | score_time: 0.0479s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9233    0.9917    0.9563      2039\n",
      "           1     0.4516    0.0769    0.1315       182\n",
      "\n",
      "    accuracy                         0.9167      2221\n",
      "   macro avg     0.6875    0.5343    0.5439      2221\n",
      "weighted avg     0.8846    0.9167    0.8887      2221\n",
      "\n",
      "\n",
      "[BEFORE exclusions | TOP-50 features] Selected 50 features (top-50)\n",
      "\n",
      "==================== BEFORE exclusions | TOP-50 features ====================\n",
      "Rows: 12000 | Pos rate: 0.08383333333333333 | Features: 50\n",
      "\n",
      "Logistic Regression\n",
      "  train_auc: 0.7596 | test_auc: 0.7077\n",
      "  train_time: 10.7067s | score_time: 0.1996s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9529    0.6717    0.7879      2199\n",
      "           1     0.1506    0.6368    0.2436       201\n",
      "\n",
      "    accuracy                         0.6687      2400\n",
      "   macro avg     0.5517    0.6542    0.5158      2400\n",
      "weighted avg     0.8857    0.6687    0.7424      2400\n",
      "\n",
      "\n",
      "Random Forest\n",
      "  train_auc: 0.9983 | test_auc: 0.7322\n",
      "  train_time: 2.8287s | score_time: 0.2442s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9188    0.9573    0.9376      2199\n",
      "           1     0.1376    0.0746    0.0968       201\n",
      "\n",
      "    accuracy                         0.8833      2400\n",
      "   macro avg     0.5282    0.5159    0.5172      2400\n",
      "weighted avg     0.8534    0.8833    0.8672      2400\n",
      "\n",
      "\n",
      "XGBoost\n",
      "  train_auc: 0.9861 | test_auc: 0.7529\n",
      "  train_time: 1.2774s | score_time: 0.0350s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9204    0.9932    0.9554      2199\n",
      "           1     0.4444    0.0597    0.1053       201\n",
      "\n",
      "    accuracy                         0.9150      2400\n",
      "   macro avg     0.6824    0.5264    0.5303      2400\n",
      "weighted avg     0.8805    0.9150    0.8842      2400\n",
      "\n",
      "\n",
      "[AFTER  exclusions | TOP-50 features] Selected 50 features (top-50)\n",
      "\n",
      "==================== AFTER  exclusions | TOP-50 features ====================\n",
      "Rows: 11102 | Pos rate: 0.08196721311475409 | Features: 50\n",
      "\n",
      "Logistic Regression\n",
      "  train_auc: 0.7702 | test_auc: 0.7613\n",
      "  train_time: 0.1408s | score_time: 0.0099s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9621    0.6974    0.8086      2039\n",
      "           1     0.1696    0.6923    0.2724       182\n",
      "\n",
      "    accuracy                         0.6970      2221\n",
      "   macro avg     0.5658    0.6949    0.5405      2221\n",
      "weighted avg     0.8972    0.6970    0.7647      2221\n",
      "\n",
      "\n",
      "Random Forest\n",
      "  train_auc: 1.0000 | test_auc: 0.7756\n",
      "  train_time: 2.7161s | score_time: 0.2404s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9215    0.9961    0.9573      2039\n",
      "           1     0.5294    0.0495    0.0905       182\n",
      "\n",
      "    accuracy                         0.9185      2221\n",
      "   macro avg     0.7255    0.5228    0.5239      2221\n",
      "weighted avg     0.8894    0.9185    0.8863      2221\n",
      "\n",
      "\n",
      "XGBoost\n",
      "  train_auc: 0.9938 | test_auc: 0.7669\n",
      "  train_time: 1.3109s | score_time: 0.0322s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9251    0.9941    0.9584      2039\n",
      "           1     0.6000    0.0989    0.1698       182\n",
      "\n",
      "    accuracy                         0.9208      2221\n",
      "   macro avg     0.7626    0.5465    0.5641      2221\n",
      "weighted avg     0.8985    0.9208    0.8938      2221\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">test_auc</th>\n",
       "      <th colspan=\"4\" halign=\"left\">train_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>AFTER  exclusions | ALL features</th>\n",
       "      <th>AFTER  exclusions | TOP-50 features</th>\n",
       "      <th>BEFORE exclusions | ALL features</th>\n",
       "      <th>BEFORE exclusions | TOP-50 features</th>\n",
       "      <th>AFTER  exclusions | ALL features</th>\n",
       "      <th>AFTER  exclusions | TOP-50 features</th>\n",
       "      <th>BEFORE exclusions | ALL features</th>\n",
       "      <th>BEFORE exclusions | TOP-50 features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.764935</td>\n",
       "      <td>0.761311</td>\n",
       "      <td>0.712574</td>\n",
       "      <td>0.707737</td>\n",
       "      <td>0.780743</td>\n",
       "      <td>0.770246</td>\n",
       "      <td>0.769939</td>\n",
       "      <td>0.759550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.786926</td>\n",
       "      <td>0.775646</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.732174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998068</td>\n",
       "      <td>0.998258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.794529</td>\n",
       "      <td>0.766940</td>\n",
       "      <td>0.756280</td>\n",
       "      <td>0.752911</td>\n",
       "      <td>0.998097</td>\n",
       "      <td>0.993808</td>\n",
       "      <td>0.992816</td>\n",
       "      <td>0.986078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            test_auc  \\\n",
       "label               AFTER  exclusions | ALL features   \n",
       "model                                                  \n",
       "Logistic Regression                         0.764935   \n",
       "Random Forest                               0.786926   \n",
       "XGBoost                                     0.794529   \n",
       "\n",
       "                                                         \\\n",
       "label               AFTER  exclusions | TOP-50 features   \n",
       "model                                                     \n",
       "Logistic Regression                            0.761311   \n",
       "Random Forest                                  0.775646   \n",
       "XGBoost                                        0.766940   \n",
       "\n",
       "                                                      \\\n",
       "label               BEFORE exclusions | ALL features   \n",
       "model                                                  \n",
       "Logistic Regression                         0.712574   \n",
       "Random Forest                               0.741935   \n",
       "XGBoost                                     0.756280   \n",
       "\n",
       "                                                         \\\n",
       "label               BEFORE exclusions | TOP-50 features   \n",
       "model                                                     \n",
       "Logistic Regression                            0.707737   \n",
       "Random Forest                                  0.732174   \n",
       "XGBoost                                        0.752911   \n",
       "\n",
       "                                           train_auc  \\\n",
       "label               AFTER  exclusions | ALL features   \n",
       "model                                                  \n",
       "Logistic Regression                         0.780743   \n",
       "Random Forest                               1.000000   \n",
       "XGBoost                                     0.998097   \n",
       "\n",
       "                                                         \\\n",
       "label               AFTER  exclusions | TOP-50 features   \n",
       "model                                                     \n",
       "Logistic Regression                            0.770246   \n",
       "Random Forest                                  1.000000   \n",
       "XGBoost                                        0.993808   \n",
       "\n",
       "                                                      \\\n",
       "label               BEFORE exclusions | ALL features   \n",
       "model                                                  \n",
       "Logistic Regression                         0.769939   \n",
       "Random Forest                               0.998068   \n",
       "XGBoost                                     0.992816   \n",
       "\n",
       "                                                         \n",
       "label               BEFORE exclusions | TOP-50 features  \n",
       "model                                                    \n",
       "Logistic Regression                            0.759550  \n",
       "Random Forest                                  0.998258  \n",
       "XGBoost                                        0.986078  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ----------------------------\n",
    "# split helper\n",
    "# ----------------------------\n",
    "def make_split(df, seed=42, test_size=0.2):\n",
    "    y = df[\"DQ_TARGET\"].astype(int)\n",
    "    X = df.drop(columns=[\"prism_consumer_id\", \"DQ_TARGET\"], errors=\"ignore\")\n",
    "    return train_test_split(X, y, test_size=test_size, stratify=y, random_state=seed)\n",
    "\n",
    "# ----------------------------\n",
    "# feature selection helper (fit on TRAIN only)\n",
    "# ----------------------------\n",
    "def select_top_k_l1(X_train, y_train, X_test, k=50, C=0.2):\n",
    "    \"\"\"\n",
    "    Fits an L1-logistic model on imputed+scaled TRAIN data to pick top-k features by abs coef.\n",
    "    Returns reduced X_train, X_test, and the selected feature names.\n",
    "    \"\"\"\n",
    "    # 1) impute + scale for selection model\n",
    "    prep = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler(with_mean=False))\n",
    "    ])\n",
    "    Xtr_p = prep.fit_transform(X_train)\n",
    "    Xte_p = prep.transform(X_test)\n",
    "\n",
    "    # 2) L1 logistic for sparse selection\n",
    "    sel_model = LogisticRegression(\n",
    "        penalty=\"l1\",\n",
    "        solver=\"liblinear\",\n",
    "        class_weight=\"balanced\",\n",
    "        C=C,\n",
    "        max_iter=3000\n",
    "    )\n",
    "    sel_model.fit(Xtr_p, y_train)\n",
    "\n",
    "    # 3) rank features by abs coefficient\n",
    "    coefs = np.abs(sel_model.coef_).ravel()\n",
    "    feat_names = np.array(X_train.columns)\n",
    "\n",
    "    # handle all-zero coef case\n",
    "    if np.all(coefs == 0):\n",
    "        # fallback: keep first k columns (better than crashing)\n",
    "        idx = np.arange(min(k, len(feat_names)))\n",
    "    else:\n",
    "        idx = np.argsort(coefs)[::-1][:min(k, len(feat_names))]\n",
    "\n",
    "    selected = feat_names[idx].tolist()\n",
    "\n",
    "    # 4) return raw (unscaled) columns subset — your model pipelines still handle impute/scale\n",
    "    return X_train[selected].copy(), X_test[selected].copy(), selected\n",
    "\n",
    "# ----------------------------\n",
    "# eval helper\n",
    "# ----------------------------\n",
    "def eval_model_full(name, model, X_train, y_train, X_test, y_test, threshold=0.5):\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(X_train, y_train)\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    t2 = time.perf_counter()\n",
    "    ytr_prob = model.predict_proba(X_train)[:, 1]\n",
    "    yte_prob = model.predict_proba(X_test)[:, 1]\n",
    "    t3 = time.perf_counter()\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, ytr_prob)\n",
    "    test_auc  = roc_auc_score(y_test,  yte_prob)\n",
    "\n",
    "    yte_pred = (yte_prob >= threshold).astype(int)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  train_auc: {train_auc:.4f} | test_auc: {test_auc:.4f}\")\n",
    "    print(f\"  train_time: {t1-t0:.4f}s | score_time: {t3-t2:.4f}s\")\n",
    "    print(classification_report(y_test, yte_pred, digits=4))\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"train_auc\": train_auc,\n",
    "        \"test_auc\": test_auc,\n",
    "        \"train_time\": t1 - t0,\n",
    "        \"score_time\": t3 - t2\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# run one experiment (optionally with feature selection)\n",
    "# ----------------------------\n",
    "def run_suite(df, label, models, threshold=0.5, use_fs=False, k=50, fs_C=0.2, seed=42):\n",
    "    X_train, X_test, y_train, y_test = make_split(df, seed=seed, test_size=0.2)\n",
    "\n",
    "    selected = None\n",
    "    if use_fs:\n",
    "        X_train, X_test, selected = select_top_k_l1(X_train, y_train, X_test, k=k, C=fs_C)\n",
    "        print(f\"\\n[{label}] Selected {len(selected)} features (top-{k})\")\n",
    "        # uncomment if you want to see them:\n",
    "        # print(selected)\n",
    "\n",
    "    results = []\n",
    "    print(f\"\\n==================== {label} ====================\")\n",
    "    print(\"Rows:\", df.shape[0], \"| Pos rate:\", df[\"DQ_TARGET\"].mean(), \"| Features:\", X_train.shape[1])\n",
    "\n",
    "    for name, model in models:\n",
    "        results.append(eval_model_full(name, model, X_train, y_train, X_test, y_test, threshold=threshold))\n",
    "\n",
    "    out = pd.DataFrame(results)\n",
    "    out[\"label\"] = label\n",
    "    out[\"use_fs\"] = use_fs\n",
    "    out[\"k\"] = (len(selected) if selected is not None else np.nan)\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# build BEFORE/AFTER datasets from df_eval_master\n",
    "# ----------------------------\n",
    "df_before = df_eval_master.drop(columns=[\"excluded\"]).copy()\n",
    "df_after  = df_eval_master.loc[~df_eval_master[\"excluded\"]].drop(columns=[\"excluded\"]).copy()\n",
    "\n",
    "# ----------------------------\n",
    "# run 4 experiments\n",
    "# ----------------------------\n",
    "res_A = run_suite(df_before, \"BEFORE exclusions | ALL features\", models, use_fs=False)\n",
    "res_B = run_suite(df_after,  \"AFTER  exclusions | ALL features\", models, use_fs=False)\n",
    "\n",
    "res_C = run_suite(df_before, \"BEFORE exclusions | TOP-50 features\", models, use_fs=True, k=50, fs_C=0.2)\n",
    "res_D = run_suite(df_after,  \"AFTER  exclusions | TOP-50 features\", models, use_fs=True, k=50, fs_C=0.2)\n",
    "\n",
    "results_4way = pd.concat([res_A, res_B, res_C, res_D], ignore_index=True)\n",
    "\n",
    "# ----------------------------\n",
    "# summary table\n",
    "# ----------------------------\n",
    "summary = results_4way.pivot_table(\n",
    "    index=\"model\",\n",
    "    columns=\"label\",\n",
    "    values=[\"test_auc\", \"train_auc\"],\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1053570d-fe03-4059-bacf-05b4e17726a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Added feature 'month_count' with AUC=0.7001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[177], line 27\u001b[0m\n\u001b[1;32m     16\u001b[0m current_feats \u001b[38;5;241m=\u001b[39m selected_features \u001b[38;5;241m+\u001b[39m [feat]\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m     19\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     20\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_feats\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m y_probs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test[current_feats])[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     30\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_probs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:1806\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1786\u001b[0m evals_result: EvalsLog \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1787\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1788\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1789\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39mfeature_types,\n\u001b[1;32m   1804\u001b[0m )\n\u001b[0;32m-> 1806\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1818\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/training.py:199\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:2434\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2433\u001b[0m     _check_call(\n\u001b[0;32m-> 2434\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2435\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2436\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2437\u001b[0m     )\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2439\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Split data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Forward Selection ---\n",
    "selected_features = []\n",
    "remaining_features = list(X.columns)\n",
    "target_feature_count = 50\n",
    "\n",
    "for i in range(target_feature_count):\n",
    "    best_auc = 0\n",
    "    best_feat = None\n",
    "    \n",
    "    for feat in remaining_features:\n",
    "        current_feats = selected_features + [feat]\n",
    "        \n",
    "        model = XGBClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            eval_metric=\"auc\",\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train[current_feats], y_train)\n",
    "        \n",
    "        y_probs = model.predict_proba(X_test[current_feats])[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_probs)\n",
    "        \n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_feat = feat\n",
    "    \n",
    "    if best_feat is None:\n",
    "        print(\"No improvement; stopping early.\")\n",
    "        break\n",
    "    \n",
    "    selected_features.append(best_feat)\n",
    "    remaining_features.remove(best_feat)\n",
    "    print(f\"Step {i+1}: Added feature '{best_feat}' with AUC={best_auc:.4f}\")\n",
    "\n",
    "# --- Final Selected Features ---\n",
    "print(\"Top 50 Selected Features:\", selected_features)\n",
    "\n",
    "# --- Train Final XGBoost Model ---\n",
    "final_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"auc\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "y_probs = final_model.predict_proba(X_test[selected_features])[:, 1]\n",
    "final_auc = roc_auc_score(y_test, y_probs)\n",
    "print(\"Final Test ROC-AUC:\", final_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93269c79-c079-4f01-b139-c80735f5fe97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f30d6c9-4268-4236-bcf8-fef802dbc3fd",
   "metadata": {},
   "source": [
    "## comparison to: no scoring exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8068c-0501-42f7-a980-31910f25eb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823505bc-af4b-4b62-ac5c-b5503c2356a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23629bcd-dd75-4204-900b-6d5cba407c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eb422e-acd7-4388-a235-8486fd63509f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ceb55-2c8c-448f-82e6-915ebc196eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
